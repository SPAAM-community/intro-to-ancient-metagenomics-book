---
title: Introduction to NGS Sequencing
author: James A. Fellows Yates
number-depth: 2
bibliography: assets/references/introduction-to-ngs-sequencing.bib
---

::: {.callout-important}
ðŸš§ This page is still under construction ðŸš§
:::

Next generation sequencing (NGS) revolutionised the whole of biology by providing rapid and cheap access to huge amounts of DNA sequence data. 
One unexpected benefit of this technology was that the technique used by Illumina sequencers was that it was also _perfect_ for sequencing ancient DNA.

In this chapter, we will do a brief overview of how DNA is structured, how DNA sequencing works, how most NGS sequenced DNA sequences are digitally represented, and then cover some of the important considerations for ancient metagenomic sequencing datasets.

## Basic Concepts

### Basic structure of DNA

To understand how sequencing works, we need to understand the basic structure of DNA.
Deoxyribonucleic acid (DNA) is a biological molecule famous for it's 'double helix' structure ([@fig-intro-ngs-fig-3dhelix]), and is present in the vast majority of cells in your body . 
It encodes all the genetic information required for the development, growth, and function of living organisms.

The each strand of the double helix structure consist of four main components called nucleotides, which bind together in different orders.
These nucleotides consist of two groups:

- Pyrimidines: cytosine (C) and thymine (T)
- Purines: guanine (G) and adenine (A)

The nucleotides on one strand are connected via a 'sugar phosphate backbone', however the two strands are held together by the interaction of the hydrogen bond pairing of four different nucleobases on each strand ([@fig-intro-ngs-fig-2dhelix]).


:::{layout-ncol=2}
![Still from animation of 3D DNA double helix. Source: Erin Rod, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed), via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:The_Structure_of_DNA_GIF.gif)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-3dhelix.png){#fig-intro-ngs-fig-3dhelix height=300px}

![2D molecular diagram of DNA helix, with sugar-phosphate backbone and amine groups labelled indicated. Source: Pradana Aumars, [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Structure_ADN.png)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-2dhelix.png){#fig-intro-ngs-fig-2dhelix height=300px}
:::

This pairing consists of one pyrimidine and one purine, which are complementary to each other.

- `C with `G` (to remember: thing CGI in animated movies)
- `A` and `T` (to remember: think AT-AT Walker from Star Wars, [@fig-intro-ngs-fig-atatwalker])

Therefore, whenever you find a `C` on one strand, you will normally find a `G` on the other strand (and vice versa), and the same for `A` and `T`.
If you find an `A` on one strand, you will find a `T` on the other strand, or if a `T` on one strand, you will have another.

What this means is that because of this complementary pairing, depending on which strand you are reading, you can always reconstruct the order bases on the _other_ strand.

![Lego construction of AT AT walker from Star Wars. Source: Tim Moreillon, [CC BY-SA 2.0 Generic](https://creativecommons.org/licenses/by-sa/2.0/deed), via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:LEGO_Star_Wars_AT-AT_Walker_(6740909421).jpg)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-atatwalker.jpg){#fig-intro-ngs-fig-atatwalker height=300px}

### DNA replication

This characteristic of the DNA molecule is a critical component on how DNA gets replicated (or copied) within a cell.

At it's core, DNA replication consists of:

1. Unwinding the DNA helix and separate the two strands by breaking the hydrogen bonds between the complementary bases using a helicase enzyme
2. Use a polymerase enzyme to add complementary new 'free' nucleotides floating in the cell to the exposed base on the strand (repeating for each base until a 'stop' signal is received)
3. Construct bonds on the sugar-phosphate backbone of the new strand using a ligase enzyme

A graphical representation can be seen in using a helicase enzyme in the image below ([@fig-intro-ngs-fig-dnareplication]).

![Schematic diagram of DNA replication, with a helicase unwinding DNA strand with DNA polymerases on the leading and lagging strand incorporating free nucleotides. Source: Christine Imiller, [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/deed), via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:DNA_Polymerase_DNA_Replication.png)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-dnareplication.jpg){#fig-intro-ngs-fig-dnareplication height=300px}

This concept is important because it is the basis of how DNA sequencing works, and how we can reconstruct the sequence of a DNA molecule.

### Extracting DNA

To understand why NGS sequencing revolutionised the field of palaeogenomics, we need to quickly need to compare a difference between how we get modern and ancient DNA.

To get DNA from 'modern' samples (i.e., living organisms), you first get your tissue.
You then have to break down (lyse) the cell membrane and/or walls, to release the molecular contents of the cell [@Danaeifar2022-sk].
Extraction protocols then use a variety of enzymes to degrade the other biomolecules in the cell (e.g., proteins, lipids, RNA) so that they do not 'interfere' with the extraction of the DNA itself.
Finally, the DNA is separated and pulled out from the rest of the now-broken cell contents (purification).

This extracted DNA are typically in very long and intact strands that you can sort of imagine as long, soft spaghetti pasta like structures ([@fig-intro-ngs-fig-moderndnaextraction]).

![Simplified schematic diagram of the process of DNA extraction from living cells. Source: CNX OpenStax, [CC BY 4.0 International](https://creativecommons.org/licenses/by/4.0/deed), via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Figure_17_01_02.jpg)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-moderndnaextraction.jpg){#fig-intro-ngs-fig-moderndnaextraction width=90%}

In contrast, while the concept of ancient DNA extraction is the similar, the end product of the extraction is different.

Taking a skeleton as an example, once you have your bone sample, cell lysis is normally not necessary as the cells are already broken down.
However, we have to instead 'liberate' the DNA from the mineral matrix of the bone - so palaeogenomicsts first demineralise the bone to release the DNA and then then degrade the remaining more robust molecules in the sample (typically just protein) before purifying the DNA [@Andreeva2022-oe].

The resulting DNA molecules are quite different from the modern DNA.
Rather than well cooked, soft spaghetti structures - ancient DNA molecules are more like extremely overcooked spaghetti. 
These molecules are highly degraded, broken down to very small fragments, and also often have 'damage' at the ends in the form of 'modified nucleotides' that do not represent the original sequence  (see the [Introduction to Ancient DNA chapter](introduction-to-ancient-dna.qmd) for more information).  
Finally, the small amount of tiny and damaged DNA molecules typically sits in a 'soup' of 'contaminating' high-quality modern DNA from the surrounding burial and storage environment ([@fig-intro-ngs-fig-ancientdnainbone]).

As we will find out in the next section, this short fragments of DNA is not a disadvantage for NGS sequencing, but rather a benefit.

![Â© [Lucy Reading-Ikkanda](https://www.lucyreading.co.uk/project/ancient-dna/) for The Scientist Magazine, June 2015 (reused here with permission). Very small fragmented 'endogenous' DNA is preserved in bone, but alongside more recent and modern contaminating microbial and recent human DNA](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-ancientdnainbone.png){#fig-intro-ngs-fig-ancientdnainbone height=600px}


### DNA sequencing

Now that we have our DNA we want to be able to 'read' the order of the nucleotide sequence that makes up the molecule.
Sequencing is the processing of converting the sequence of the four chemical nucleotides to the `ACTG` you can see on your computer screen.
The result of this process is the essentially what we do pretty much all of our analyses on in genetics and genomics.

The core concept of most NGS sequencing methods ^[Newer techniques such as Nanopore sequencers use different methods.] is to replicate the strand, but when adding a nucleotide, you instead supply a modified nucleotide with a fluorophore attached to it.
This fluorophore is a small molecule that emits a specific colour when excited by a laser.
As you have four different nucleotides, each will emit a different colour [@Ju2006-cl].
Therefore if you record the colour emitted light each time the modified nucleotide is added to a strand, you can reconstruct the sequence of the DNA molecule ([@fig-intro-ngs-fig-colourednucleotides]).

![Molecular diagram of the four DNA nucleotides with coloured fluorophore amine groups. Source: [@Ju2006-cl]](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-colourednucleotides.jpeg){#fig-intro-ngs-fig-colourednucleotides height=600px}

### Sanger sequencing

Historically, the first mass-production sequenced method was Sanger sequencing ([@fig-intro-ngs-fig-sangersequencing]) [@Sanger1977-zw].
This was the method used for sequenced the first human genome under the Human Genome Project [@Heather2015-zo]

The concept of Sanger sequencing involves making lots of copies of a single DNA molecule using replication. 
But when adding the nucleotides, you include within the mixture of (normal) free nucleotides, you include a few modified nucleotides that include fluorophore, but also that also have a 'blocking' component that prevents any additional nucleotides from being added to the strand of that _particular copy_ by the polymerase.
Critically, the point at which a blocking nucleotide is incorporated is random.
As there is only a small proportion of blocking nucleotides in amongst pool of free nucleotides,the incorporation of the blocking nucleotides occurs at a slow rate and at different points during the replication process.
This results in many replicated molecules but all of different lengths ([@fig-intro-ngs-fig-sangersequencing]).

![Diagram of sanger sequencing, with a primer, template and free blocking nucleotides being added to ends of molecules at random lengths, and then being sent through a size-selecting capillary with a laser dector to identify which of the four blocking nucleotides are passing through the capillary and thus ready ina  chromatopgraph. Source: Estevezj, [CC BY-SA 3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/) via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Sanger-sequencing.svg)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-sangersequencing.png){#fig-intro-ngs-fig-sangersequencing height=300px}

Once you have the replicated molecules, Sanger sequencing involves running the mixture through a capillary gel.
As all the molecules are of different lengths, they will move through the gel at different speeds, and therefore separate out.
A laser is then fired at the gel at regular intervals, and the light emitted from the fluorophores is detected.
Shorter molecules will move faster through the gel, and therefore will be detected first, whereas longer molecules will be detected later.
Therefore, by detecting the light emitted as the incrementally longer molecules pass through the gel, you can reconstruct the sequence of the nucleotides along the module.

The result is a chromatogram, which is a graph that records the strength of each colour at each point in the gel band ([@fig-intro-ngs-fig-chromatogram]).

![Example of gel-based chromatogram with four columns with bands indicating which colour is the blocking nucleotide of that particular sized DNA molecule, and on the size an intensity graph of each colour given off by each flourophore to indicate which colour it is. Source: Morse Phoque (Abizar), [CC BY-SA 3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/) via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Radioactive_Fluorescent_Seq.jpg)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-chromatogram.jpg){#fig-intro-ngs-fig-chromatogram height=300px}

While this method was used for the first sequencing human genome, it was very slow and very expensive - it does not scale well  [@Schloss2020-gp] due to having to make many copies of a single molecule and sequence each nucleotide sequence one at a time.

Furthermore, the method requires a large amount of starting DNA.
However due to the degraded nature of ancient DNA, it is very rare to have sufficient concentration of DNA to be able to use Sanger sequencing.

## Next generation sequencing

In 2005, the first 'Next Generation Sequencing' (NGS) machines were released ^[With the more recent emergence of Nanopore sequencing, really NGS should be equated to 'second generation sequencing', a term you will see in some contexts.] in the form of Roche's 454 Pyrosequencing [@Heather2015-zo].

These new sequencers were able to quickly and cheaply sequence millions of DNA molecules at once, revolutionising genetics and enabling 'accessible' genomics to a much wider set of scientists.

While a few companies emerged with their own NGS machines, such as PacBio and IonTorrent, sequencers from Illumina have been by far the been the most successful.
These machines have been so successful, they have almost exclusively sequenced the entire corpus of ancient DNA sequence data.
Therefore the rest of this chapter will focus just on Illumina sequencing.

### Illumina sequencing 

Illumina sequencing relies on a process termed 'Sequencing by synthesis' (SBS) using reversible terminators.
This follows a similar concept as Sanger Sequencing in that you add modified nucleotides with fluorophores, however instead of using multiple molecules with different blocking separated via gel, it uses nucleotides that can be reversibly blocked and thus continue incorporating nucleotides in a single molecule [@Bentley2008-oj].

This works by immobilising the DNA so it stays on one location on a special type of plate.
The machine then performs out a typical DNA replication, adding the flourophore modified nucleotides one at a time, and then taking a photo of the emitted light.
However the key difference is the blocking part of the oligo is removed, so the next modified oligo is added.

To visualise how this looks like, you can imagine a plate upon which you see millions of coloured tiny dots ([@fig-intro-ngs-fig-flowcell]), each cycling in realtime through different colours as each new nucleotide is added. 

![Graphical representation of an Illumina sequencing flowcell during sequencing. Each colour dot corresponds to a single cluster of copies of the same DNA molecule emitting light corresponding to a single nucleotide along the molecular sequence.](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-flowcell.png){#fig-intro-ngs-fig-flowcell height=300px}

To follow this however, the DNA needs to be prepared in a specific way.

### Flow cells and adapters

To ensure the DNA molecules do not move while taking photos, in Illumina sequencing, the DNA molecules are bound to a special glass slide called a flowcell.
This also ensures the DNA does not get washed away during the sequencing process as different solutions wash through the machine between each step.

![Photo of a lawn of grass, as a metaphor of the 'lawn' of artificial oligonucleotide sequences of an Illumina flowcell. Source: Animaldetector, [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Seededfertilizedlawn.JPG)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-grassy-lawn.jpg){#fig-intro-ngs-fig-grassy-lawn height=300px}

<!-- TODO SEE IF CAN REPRODUCE OR MAKE OWN VERSION OF FLOW CELL IMAGE -->

To immobilise the DNA, the flow cell is coated with a 'lawn' of synthetic oligonucleotides (i.e., custom sequences made in a lab)  [@Holt2008-wk].
By attaching (ligating) the _complementary_ sequence of the synthetic oligonucleotides to your DNA molecules from your sample, when your DNA molecules flow over the lawn, the complementary bonds between the nucleotide pairs will form.
This then will hold the DNA in place.

The process of adding the complementary synthetic oligonucleotides (often referred to as oligos), called 'Adapters', is called 'Library preparation'.
These adapters sequences do not only include the complementary sequence to flowcell oligos, but also an additional sequence that acts as a priming site for polymerases to start the replication process
Furthermore, researchers have exploited the highly-multiplex nature of Illumina sequence to allow them to sequence multiple samples at once.
They do this by adding additional sequences to the adapter sequence construct that consist of short sample-specific 'indices' or 'barcodes'.
These indices allow DNA molecules from different samples to be sequenced at the same time and then separated back into the groups of molecules from the same samples during data analysis.

The completed index, adapter, and DNA molecule construction is termed a library, and is what is put into the sequencing machine. and what can in this form be immobilised on the flow cell.

<!-- TODO INSERT ILLUMINA DNA CONSTRUCT FROM TINA -->


In the image above <!-- TODO TO DESCRIBE ONCE WE HAVE THE IMAGE And also, when you're sequencing multiple samples at once on the same sequencing run, you can add things called indices, or known as barcodes, which are basically sample specific. So it allows you to mix multiple samples at once into one sequencing run, sequencing all at the same time, later on separate them out. So this is ultimately a slightly simplified version of a Illuminate DNA construct. So the X, X, X, X, X in the middle, this is your target. So this is actually your DNA sequence from your sample. And then at both ends, you essentially have a target primer. So this is where your polymerase will bind onto to start, then actually going, reading into your target, or your insert is another phrase that you can call it. Then prior to the target primer, you also have an index. So this is actually your sample specific barcode. This is actually added typically onto the adapter, and so this happens in the, no, sorry. And the library construction, sorry. And then also you have the adapter and index primer right at the beginning. So this is both what binds onto your flow cell, but also acts as a primer for actually reading the index because you also need a sequence index to know which DNA molecule, to which sample DNA molecule it's coming from. --> 

### Clustering

Now that each DNA molecule of the library is bound to it's own section of the flowcell, we have the problem that the light emitted from a single tiny fluorophore will not be strong enough to be captured by the camera in the sequencer.

Illumina machines get around this through a process called 'clustering'.
The clustering process will make many copies of the exact same DNA molecule right next to the original template molecule.
When the cluster of DNA copies emit the light from the same nucleotide along their sequence at the same time, collectively the light emitted will now be sufficiently strong to be captured by the camera.

To make copies sufficient copies of the 'template' molecule, clustering is carried out using 'bridge amplification' [@Bentley2008-oj].

The process of bridge amplification is as follows:

1. A single-stranded DNA molecule is immobilised on the flow cell via the oligo adapter on _one_ end of the module
2. The DNA is bent over
3. The oligo adapter on the other end of the molecule binds to the other complementary flow-cell oligo adapter in the close vicinity to the template (forming a bridge)
4. A priming sequence, free nucleotides, and a polymerase is added to the flow cell
5. The reverse complement of the DNA molecule is made via replication, and the polymerase mixture is washed away
6. The two strands are then separated to form two single-stranded DNA molecules (the new one the reverse complement of the original template molecule)
7. Repeat 1-5 for the two new strands until sufficient copies are made

This process is also depicted in [@fig-intro-ngs-fig-bridgeamplification.png].

![Diagram of bridge amplification. Source: DMLapato, [CC BY-SA 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/) via [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Cluster_Generation.png)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-bridgeamplification.png){#fig-intro-ngs-fig-bridgeamplification.png height=600px}

Of course, at the stage that you've had many cycles of replication, you have in a single cluster both forward and reverse complement copies of the same DNA molecule.
As this would emit different colours at each position along the sequence, one of the strand directions are removed but 'trimming' the flow cell lawn at one of the complementary oligo adapter sequences

### Sequencing-by-synthesis

With our cluster of many copies of the same DNA molecule, we can now start the 'Sequencing by synthesis' (SBS) process itself.

As with replication and Sanger sequencing, the process SBS involves adding free nucleotides to the template strand (with only the complementary base being able to be incorporated to the exposed strand), some of which are modified to emit light when excited with a laser, and taking a picture [@Bentley2008-oj].

The main difference with Sanger sequencing is you can actually reuse the same DNA molecule to add more nucleotides along the same strand - rather than 'discarding' it with permanently blocking nucleotides. 
This makes the SBS technique more resource sufficient, both in reagents (you need fewer copies of the molecule and recycle the same original copies of template molecules), but also in space - you don't have to separate out the molecules in a gel - they are all fixed on the flowcell in a tightly packed layout.

![Diagram of sequencing by synthesis. Source: Abizar Lakdawalla, [CC BY-SA 3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/) via [Wikimedia Commons](https://en.wikipedia.org/wiki/File:Sequencing_by_synthesis_Reversible_terminators.png)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-sequencingbysynthesis.png){#fig-intro-ngs-fig-sequencingbysynthesis height=300px}

The process as in @fig-intro-ngs-fig-sequencingbysynthesis can be broken down to:

1. On a single stranded molecule, bind a primer on the molecule's adapter priming site
2. Add fluorescently labelled nucleotides (with a reversible terminator) to the flow cell
3. Only complementary nucleotides will bind to the template strand at the first exposed base
4. Wash away unbound nucleotides
5. Fire a laser to excite the modified nucleotides to emit the corresponding colour, and take a picture
6. Clip off the fluorophore part of the nucleotide
7. Repeat 2-6 until the entire strand is sequenced

On Illumina sequencers, the number of repetitions (known as cycles) and images typically happens either 50, 75, or 125 times, depending on the machine and the type of sequencing chemistry kit.

The reason why Illumina sequencers (and similar NGS technologies) have been so successful is that this process is happening across millions of clusters at the same time.

![Diagram of sequencing by synthesis. Source: EBI Training, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) via [EBI Training](https://www.ebi.ac.uk/training/online/courses/functional-genomics-ii-common-technologies-and-data-analysis-methods/next-generation-sequencing/second-generation-sequencing/illumina-sequencing/)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-sbsimagecapture.png){#fig-intro-ngs-fig-sbsimagecapture height=300px}

You can see a small fraction of this flow cell in @fig-intro-ngs-fig-sbsimagecapture.
Each coloured dot corresponds to a cluster of DNA molecules.
At each cycle (each photo), a new nucleotide is added to the strand, and a laser is fired to excite the fluorophores.
You can see two different clusters emit different lights, as they are different DNA molecules thus have different nucleotides at that particular 'cycle' of the 'replication' process.
By converting the emitted light to the known corresponding A, C, G, T, at each photo you can reconstruct the sequence of the DNA molecule.

By now you probably are starting to feel comfortable with the concept for one-colour equals one nucleotide.
To throw a curve ball, Illumina sequencers actually have _three_ different 'colour chemistries' they use on different machines.

### Colour chemistry

To be able to offer cheaper machines, Illumina came up with a system that requires the number of colours that need to be detected.
These variants are often referred to different 'colour chemistries'.

A list of Illumina platforms and their colour chemistries as follows below:

- Four-colour chemistry
    - Illumina HiSeq
    - Illumina MiSeq
- Two-colour chemistry
    - Illumina NovaSeq
    - Illumina NextSeq
- One-colour chemistry
    - Illumina iSeq

In the vast majority of cases, your data will be sequenced on only four- and two-colour chemistries, so we will focus on these two.

In the case of the Illumina HiSeq and MiSeq platforms, the system for sequencing is as described previously: each of the four bases of the nucleotides that make up DNA will have a reversible-terminator variant, and each of these variants will have a fluorophore that will emit one of four colours.
Therefore, the camera on the machine is designed to be able to pick up each of the four different wavelengths through different imaging channels.

In contrast, two-colour chemistry machines will only have imaging channels that detect have two dye colours - red and green ([@fig-intro-ngs-fig-twocolourchemistry]). 
If the machine detects green being emitted from a cluster on the flowcell, this correspond to T.
If the machine detects red, it records a C. 
If the machine detects _both_ red and green wavelengths being emitted from a cluster - this corresponds to an A.
If no colour is emitted, this is _assumed to be a G_. 

![Graphical representation of difference between four- (left) and two-colour (right) chemistry of Illumina Platforms. Inspired by [https://www.ecseq.com/support/ngs/do_you_have_two_colors_or_four_colors_in_Illumina](https://www.ecseq.com/support/ngs/do_you_have_two_colors_or_four_colors_in_Illumina)](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-twocolourchemistry.png){#fig-intro-ngs-fig-twocolourchemistry height=300px}

This characteristic of two colour-chemistry thus means you must be aware of the type of sequencer your data was generated on, as this will require slightly different preprocessing as we will see later on in the section [Low sequence diversity](#low-sequence-diversity).

### Base quality and paired-end sequencing

Another consideration with Illumina sequencing kits is not just the number of cycles, but which kit to use based on its 'pairment'.

As I'm sure everyone readying this book has experienced, biology is not like physics where everything is perfect and 'easy'.
Biology is messy, things do not stay stable.
The same applies to sequencing - as the sequencer goes through each cycle of adding a new nucleotide to each DNA strand in a cluster, mistakes will increasingly start happening as polymerases don't bind properly, fall off, skip nucleotides, or even add the wrong base.
The accumulated effects of these mistakes across all DNA strands in a cluster is that the emitted light during the imaging part of the cycle becomes less clearly one colour as mixtures of wavelengths are emitted.
Thus, the confidence of the _correct_ nucleotide has been recorded at that position of the DNA molecule becomes less.

(Illumina) sequencers address this in two ways.

Firstly, when measuring the particular base being recorded, all sequencers will at the same time record a 'base quality' that is associated with that call.
This corresponds to the confidence (via a probability) that the recorded base was the correct one.
For example, if the wavelength was mostly one colour (let's say red for C) but the camera picked up a bit of another colour (lets say green for T), it will record `C` in the output, but the base quality score will be lower.
If the sequencer's camera picks up wavelengths of all four colours from the same cluster at the same time - or even no light is detected at all - then the base quality for that position in that DNA molecule will be recorded as an N and a base quality of 0.

Secondly, specifically for Illumina sequencers, there is the concept of 'paired-end' sequencing [@Bentley2008-oj].
As there is an overall drop in base quality (i.e., confidence we have the right nucleotide) the closer we get to the end of the molecule due to the accumulated mistakes over time, we can freshly sequence the molecule again but in the _reverse_ direction.
This way, we can 'merge' or average the base quality scores of two independent 'observations' of the nucleotide at that position.
So if the last base when reading the molecule in the forward direction is an N (due to ambiguous wavelength emission), we can correct or 'recover' this last base by making it the _first_ base we call in when sequencing in the reverse direction from scratch with fresh reagents.

This works as, Illumina sequencers can conveniently re-use the bending over approach as performed by the 'bridge' amplification method of clustering we saw earlier in this chapter.
I.e., after bending over, the opposite flowcell olgio from the forward reverse flowcell anchor is cut so the 'end' of the original molecule is now bound to the flow cell.

This paired-end sequencing technique means you get a pair of files - both with the same sequence from each cluster, but one has the molecule 'read' in the forward direction, and the other file with the 'reverse' direction. 

Another added benefit of paired-end sequencing is that you can recover longer molecules.
In cases where the DNA molecule is _longer_ than the number of cycles the chemistry kit being used, by flipping the over the molecule and sequencing from the other end you can recover the end of the molecule.
Of course if the molecule is longer than the sum of both set of cycles (e.g. a 120bp molecule, even though the sequencing kit is only two times 50bp), you will miss the 'middle' part of the molecule.
However this is counteracted by the sheer number of independent molecules sequenced, so the 'missing' part can be filled in from another sequencing DNA molecule.

<!-- TODO: add paired end sequencing image -->

It should be noted, however, the added benefit of sequencing longer molecules via paired-end sequencing is not so relevant to ancient DNA or ancient metagenomics.
This is because most 'true' DNA molecules are often _shorter_ than the sequencing cycles of a typical Illumina kit.

### Base calling and demultiplexing

We should now understand how the machine itself 'reads' the DNA molecule clusters on the flow cell.

But how does these images get converted to a format that you can read on your computer screen?
And if you have sequenced multiple samples at the same time (each with their own sample-specific indices), how do you separate these out?

Base calling is the process of converting the images to digital text-based `A`, `C`, `T,` and `G`s.
This is not something the vast majority of researchers have to do as it nowadays happens on the sequencer itself and thus the process is not particularly relevant for us. 

However, once the file with the digital representations of the sequences is taken off the machine, typically a sequencing technician or bioinformatician at the sequencing center, but sometimes a student, will perform something called 'demultiplexing'.
This is where the person doing the demultiplexing will run the file through a tool that identifies the known index sequence at the beginning of each read entry in the file, and put all reads containing the same sample-specific index into it's own independent file.

<!-- TODO: Add demultiplexing image --> 

While this is not something most researchers will do themselves, it is useful to know as errors detected in downstream analysis can be traced back to suboptimal demultiplexing (such as incorrect assignment of indices, if you have not the number of sequenced reads you expected).

### FASTQ File

The primary output from demultiplexing is called FASTQ file.
This is a text-based (semi-)standard format for storing biological sequences, and their corresponding base quality scores.
A biological sequence that has been converted to a digital text format is referred to as a 'read' or 'sequence read'. 
The files that stored reads are typically compressed to save space, but can be very large (gigabytes in size, even when compressed).

The structure of a FASTQ file is a repeated set of four specific lines (@fig-intro-ngs-fig-sequencing-read):

1. A metadata or ID line
2. The sequence itself
3. A 'spacer' line
4. The base quality score (corresponding to the base in the same position as in line 2)

The metadata line records a range of information from the sequencer and also potentially the demultiplexing.
Typically this line will record the sequencing machine ID, a run number, the ID of the flow cell, coordinate information from which cluster on the flow cell the particular sequence is from, and then extra information that depends on the sequencing center (e.g., some will record the sample-specific index pairs here, or certain settings of the demultiplexing tool).

![Annotated example of a single sequencing read as represented in a FASTQ file. A read consists of four lines: a metadata line, a sequence line, a spacer line, and a base quality score line. This set of four lines is repeated for every sequenced molecule in the library.](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-sequencing-read.png){#fig-intro-ngs-fig-sequencing-read width=90%}

The sequence line will contain `A`, `C`, `T`, `G`, and `N` characters in the order of the DNA molecule as recorded by the sequencer.
In the figure you can see an example of an `N` call in the first position.
It is actually quite common to see in the first or second position of reads, as the sequencer's camera is still calibrating itself. 

The third line is simply a spacer line, which is just a `+` sign.
It serves no purpose in modern day FASTQ files (they just display the `+` to reduce file size), however in the past the metadata information was duplicated on this line to associate with the base quality scores on line 4.

The fourth line has the base quality scores corresponding to the sequence in line 2.
These are encoded using [ASCII characters](https://en.wikipedia.org/wiki/ASCII) (to ensure you can encode in a single character a score more than 9).
What the exact each ASCII character represents slightly depends on [which sequencing machine you are using](https://en.wikipedia.org/wiki/FASTQ_format#Encoding) (e.g. Illumina have both a 1.3 and 1.8 variant).
However all variants encode a quality score of 'Q' also known as a 'Phred' score which corresponds to the probability of the called base is _incorrect_.
This essentially means that the lower the probability the base is incorrect, the higher the quality score.
Modern Illumina sequencers have a minimum quality score of 0 (i.e., an incorrect call) score of 41 (a highly confident call).
Wikipedia provides a very good summary of the differences between ASCII representations of the Phred score [here](https://en.wikipedia.org/wiki/FASTQ_format#Encoding). 

The rest of a FASTQ file is simply just a repeated set of these four lines.
Each line corresponds to an independent DNA cluster - and thus DNA molecule - that was sequenced.
In the case of Illumina pair-end sequencing, you will normally have two FASTQ files for each sample - and you can match the forward and reverse reading of each strand by the metadata line and a `/1` or `/2` at the end of the ID[^1].

[^1]: You can occasionally see a format called 'interleaved' FASTQ files. This is where the forward and reverse reads are placed right after one another in the same file, but this is not common practice any more. 

## Sequencing and considerations for ancient metagenomics

In the second half of this chapter, we will look into some implications of the sequencing process for analysing ancient metagenomic data.

While some of these points are not always specific to ancient metagenomics, and can apply to any DNA analysis - modern or ancient - they can be particularly impactful due to the particular characteristics of ancient DNA.

### Low DNA preservation

One side effect of the degradation and lost of DNA molecules in ancient samples is that the total molecular biomass of the sample is very low.

This means that during library preparation, researchers often have to perform many rounds of PCR amplification to get a sufficient library concentration for sequencing. 

By over-amplifying libraries, you reduce the number of unique sequences from your sample you actually retrieve.
If you are repeatedly sequencing the same DNA sequence (i.e. the amplified copies) over and over, you use up the fixed number of available clusters on the flow cell, and prevent clusters of unique sequences from being sequenced.

This is also important analysis wise, as will be discussed in the chapter on taxonomic profiling and genomic mapping, you can actually artificially 'inflate' the counts of reads that come from a particular taxon (@fig-intro-ngs-fig-sequencing-read).
For microbiome studies, this can skew the estimate of which species are in your sample or not.
Some studies have also suggested dedeuplication can improve the accuracy of metagenomic _de novo_ assembly [@Zhang2023-vz]

![Schematic representation of the result on over-amplification on reference-based genome mapping. Exact duplicate reads (yellow) that derive from overamplifying a library, can result in portions of the genome having higher depth coverage in certain regions (top distribution) and thus artificially provide a misleading sense of confidence in recovered regions during analysis, even though the overall coverage is low.](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-sequencing-read.png){#fig-intro-ngs-fig-sequencing-read}

While this artefact can be partially corrected in analysis through the process of 'deduplication', you should be careful to not overamplify your libraries in the first place as you can potentially waste a lot of money.

### Index hopping

A more recent artefact that has appeared in more recent Illumina platforms is something that has been termed 'index hopping' [@Van_der_Valk2019-to].
This can cause problems when you are multiplex sequencing samples, i.e., sequencing multiple samples at once on the same flow cell.

Some more recent Illumina platforms such as the HiSeq X and NovaSeq machines have a new type of flow cell called 'patterned flow cells'.
These aim to better separate out and make more consistent the layout of DNA clusters on the flow cell by having  'nanowells' that the clusters form within.
By having a stricter pattern where clusters form, it allows even tighter distribution of clusters on the flow cell without impeding on each other and thus increasing the number of clusters that can be sequenced at once.

However, even though the cause it not fully understood, it appears that the method used to prevent two DNA molecules entering he same well ('exclusion amplification)' can accidentally cause 'switching' of the index barcode between two different DNA molecules. 
Thus, DNA molecules from one sample can instead receive the index barcode of another sample, and subsequently assigned to the wrong sample during demultiplexing.

While this has been observed a low rates in earlier Illumina platforms, index misassignment appears to occur more often in patterned flow cells, somewhere between 0%-10% [@Van_der_Valk2019-to].

For (ancient) metagenomics this can be problem as it can result in false positive identification of taxa in your sample.
For example, this can be a particular problem if you sequencing in the same run a capture-library of a pathogen, with a shotgun metagenomic library for screening.
With index hopping, some of the abundant pathogen reads in the pathogen will be accidentally assigned in demultiplexing to the shotgun metagenomic library giving a false positive identification of the pathogen in the screening sample.
In another case, if you have an oral microbiome sample and a gut microbiome sample sequenced on the same run, you may start seeing oral species being detected up in your gut samples.
While this _could_ be valid biologically, but in other cases this could be false and it becomes hard to disambiguate if the species is truly present in the gut or not.

<!-- TODO add index hopping image -->

Therefore, you should keep this in mind when sending your libraries for sequencing.
One way around this is to add additional (short) 'inline' barcodes that ligate directly to the DNA molecules during library preparation _prior_ adapting of the index-library construct.
However this adds cost, and reduces the length of the template molecule you can sequence (as must include the inline barcode in the number of sequencing cycles).
Otherwise, good sequencing core facilities should automatically screen for this artefact when using these platforms, however you should always verify this if you find interesting results in your data.

### Sequencing errors

As many parts of this textbook demonstrates, metagenomic sequencing is becoming extremely high-throughput and analysis is becoming increasingly automated and routine.
However this does not mean you should skip over quality control of your sequencing data.

While Illumina sequencers have a very low error rate, this are not perfect  - we have already seen the paired-end sequencing approach for correcting for terminal error accumulation - and things can also go wrong during the sequencing process (@fig-intro-ngs-fig-fastqc).

All sequencing machines will record their confidence in the base calls the make, so it is still critical that researchers quality check these before performing downstream analyses.

If your reads have a high number of errors, the machine has possibly picked up the wrong nucleotide in the sequence.
This could cause a range of problems in various aspects of data analysis: your read to false have a sequence that is more similar to another organism if comparing against a reference database, potentially place the read in the wrong place during mapping (or not align at all!), prevent sufficient overlap of sequences during assembling causing fragmented assemblies, or even cause false positive variant calls during genotyping for phylogenomic analysis.

This is a particular concern for ancient metagenomics due to the very low number of truly endogenous ancient molecules in our libraries.
The low number of reads means that we cannot as easily 'correct' for errors through having many repeated observations of a base call in the same a position from independent DNA molecules.

Many core sequencing facilities will mostly handle modern samples with high quality libraries, and thus the threshold for a rejected sequencing run maybe lower than what you would want for ancient metagenomics. 
Therefore it's always important to _always_ (or double)check the quality of your sequencing data before proceeding with any analysis.

![Screenshot of the output of the sequencing quality evaluation tool FASTQC [@Andrews2010-pd] of the ancient DNA palaeofaeces sample 2612 from @Maixner2021-sg. Many of the reads have low quality scores (Y-axis) at the end of molecules (X-axis) from around 110bp. This likely represents error accumulation as the sequencing chemistry becomes 'tired'. Such low-quality bases should be removed using base quality score trimming to reduce the chance of incorrect read assignment or false-positive variant calls due to the wrong base being called.](assets/images/chapters/intro-to-ngs/fig-intro-ngs-fig-fastqc.png){#fig-intro-ngs-fig-fastqc}

### Dirty Genomes

Another very common problem we encounter in both ancient and modern metagenomics are 'dirty genomes'.

To briefly jump ahead into the bioinformatic analysis of an ancient metagenomic project, we will often compare our reads against a reference database of genomes.
This is done to classify which species' organism a particular read comes from, and allows us to infer something about the taxonomic composition of the sample.

We pull these reference genomes from a range of user-submitted databases, such as the NCBI's GenBank or RefSeq databases.
However, the genomes that are uploaded to these databases are not always of high quality.
While the NCBI does have quality control checks in place, these have not always been as stringent in the past, and are constantly evolving.

This means that some genomes in these databases are 'dirty' - i.e., they contain sequences that should not be there, such as adapters, primers, contaminating sequences from other species, or other artefactual sequences [@Longo2011-qd;@Mukherjee2015-vc;@Merchant2014-eu;@Steinegger2020-br;@Breitwieser2019-iz;@Kryukov2016-my].

A common example, which many ancient metagenomicists have encountered is repeated identificiation of _Cyprinus carpio_ (carp) in their samples.
This is not a true hit, but in fact repeated false positive hits due to the presence of adapter sequences in the carp genome ^[See [https://web.archive.org/web/20170823143538/http://www.opiniomics.org/we-need-to-stop-making-this-simple-fcking-mistake/](https://web.archive.org/web/20170823143538/http://www.opiniomics.org/we-need-to-stop-making-this-simple-fcking-mistake/) and [https://web.archive.org/web/20241012070028/https://grahametherington.blogspot.com/2014/09/why-you-should-qc-your-reads-and-your.html](https://web.archive.org/web/20241012070028/https://grahametherington.blogspot.com/2014/09/why-you-should-qc-your-reads-and-your.html)].

The implication for ancient metagenomicsists is that if you do not properly remove artefacts from your reads, you can end up with a lot of false positive hits in your data.
This can be particularly impactful, for example, if you are trying to identify the presence of dietary species in a human microbiome sample.
But this also extends to microbes, where insufficient removal of contaminating DNA (e.g. modern human sequences incorporated during sampling) can align against stretches of human sequences incorporated into chimeric reference microbial genomes. 

Therefore, while it always good to quality control check the genomes going into your reference database, you should also also thoroughly quality control your sequenced reads _prior_ downstream analysis.
So make sure you do trim reads of adapters, remove host contamination, and other artefacts, and check these steps worked properly! 


### Low Sequence Diversity Reads

The presence of low sequence diversity reads in a FASTQ file can cause degraded computational performance, and skew higher-level taxonomic assignments.

Low sequence diversity reads are those that have very little nucleotide variation, such as mononucleotide (`GGGGGG`) or dinucleotide (`ATATAT`) repeats.

While some of these are not necessarily errors (long stretches of repeats occur naturally in particularly eukaryotic genomes), they can also be caused by the type of sequencer used.

As described earlier in this chapter, Illumina NovaSeq and NextSeq platforms use two-colour chemistry.
In this system, if no light is detected by the camera, the sequencer assumes the base is a `G`.
Therefore if the molecule is very short, once the molecule finishes and there are still remaining sequencing cycles to go, there will be repeated cycles of no light being emitted ^[See: [https://support.illumina.com/content/dam/illumina-support/help/Illumina_DRAGEN_Bio_IT_Platform_v3_7_1000000141465/Content/SW/Informatics/Dragen/PolyG_Trimming_fDG.htm](https://support.illumina.com/content/dam/illumina-support/help/Illumina_DRAGEN_Bio_IT_Platform_v3_7_1000000141465/Content/SW/Informatics/Dragen/PolyG_Trimming_fDG.htm)].
This results in poly-`G` 'tails' in reads.

Ancient DNA libraries are particularly susceptible to poly-`G` tails, as the degraded nature of the molecules means that a large number of _are_ very short and thus the length of molecule finishes before all the cycles have finished.

The impact of these low sequence diversity reads is two-fold.
Firstly, they slow down processing of reads during computationally expensive alignment of eukaryotic genomes, as low sequence diversity reads can often match many different locations thus resulting in an unspecific or ambiguous alignment.
These often do not not provide useful information, and discarded from downstream analysis but only after the computational resources have been used to align them in the first place.
Secondly, you can also end up _losing_ otherwise valid reads, purely due to half of the read has an artefactual stretch of nucleotides at the end of short reads (e.g. `AGTCTCGATGGGGGGGGGG`, where the first half is a valid sequence and the tail is just because the sequence is short) and thus cannot be aligned to any part of a reference genome.
For taxonomic profiling, reads that match multiple genomes will be pushed up by Lowest Common Ancestor algorithms 'up' the taxonomic tree.
When comparing taxonomic profiles between samples at higher ranks, this can inflate counts at higher nodes (e.g., kingdom or phylum level) that do not accurately reflect the true diversity of the sample as ultimately such reads are sequencing artefacts.

Therefore, if you have sequencing data (particularly from Illumina two-colour chemistry platforms), it is a good idea to check for signatures of increased low sequence diversity reads and remove these from your data through poly-G trimming.
Read processing tools such as `fastp` [@Chen2018-vg] can help with this, as they have functionality that can automatically detect and remove poly-`G` tails from reads.

## Summary

In this chapter we have covered how the structure of DNA molecules and process of replication is critical to understanding how genetic sequencing works.

We looked at how library preparation is required to add adapters that can include sample specific barcodes to immobilise DNA molecules to the flow cell. We also went through the differences between four- and two-colour Illumina sequencing chemistry, which differ on how each nucleotide added emits a light captured by a camera.

We discussed how sequencing methods are not perfect, and how the confidence in base calls are stored in FASTQ files, and how such low confidence calls can be corrected through paired-end sequencing. 

Finally we discussed some important considerations ancient DNA and ancient metagenomics, including duplicated sequences, index hopping, sequencing errors, causes behind contaminated reference genomes, and poly-G tails in low sequence diversity reads.

## Readings

### Reviews

[@Schuster2008-qx]

[@Shendure2008-fh]

[@Slatko2018-hg]

[@Van_Dijk2014-ep]

### Sequencing Library Construction

[@Kircher2012-fg]

[@Meyer2010-qc]

### Errors and Considerations

[@Ma2019-lg]

[@Sinha2017-zo]

[@Van_der_Valk2019-to]

## Questions to think about

- Why is Illumina sequencing technologies useful for aDNA?
- What problems can the four-colour chemistry technology of NextSeq and NovaSeqs cause in downstream analysis?
- Why is 'Index-Hopping' a problem?
- What is good software to evaluate the quality of your sequencing runs?

## References