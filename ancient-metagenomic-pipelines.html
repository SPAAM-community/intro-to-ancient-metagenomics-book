<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="James A. Fellows Yates, Megan Michel, Nikolay Oskolkov">

<title>17&nbsp; Ancient Metagenomic Pipelines – Introduction to Ancient Metagenomics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./deprecated-chapters.html" rel="next">
<link href="./accessing-ancient-metagenomic-data.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-da2627e0443814779427cdd574274bae.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta property="og:title" content="17&nbsp; Ancient Metagenomic Pipelines – Introduction to Ancient Metagenomics">
<meta property="og:description" content="">
<meta property="og:image" content="https://spaam-community.github.org/intro-to-ancient-metagenomics-book/assets/images/chapters/ancient-metagenomic-pipelines/eager2_metromap_complex.png">
<meta property="og:site_name" content="Introduction to Ancient Metagenomics">
<meta property="og:image:height" content="2008">
<meta property="og:image:width" content="3742">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./section-ancient-metagenomic-resources.html">Ancient Metagenomic Resources</a></li><li class="breadcrumb-item"><a href="./ancient-metagenomic-pipelines.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Ancient Metagenomic Pipelines</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Ancient Metagenomics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./citing-this-book.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Citing this book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./authors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Authors</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./before-you-start.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Before you Start</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./section-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-ngs-sequencing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to NGS Sequencing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-ancient-dna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Ancient DNA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-metagenomics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Metagenomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-microbial-genomics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to Microbial Genomics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction-to-edna.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Environmental DNA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./section-useful-skills.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Useful Skills</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bare-bones-bash.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to the Command Line</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-tidyverse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to R and the Tidyverse</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./python-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Python and Pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./git-github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Git(Hub)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./section-ancient-metagenomics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancient Metagenomics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./taxonomic-profiling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Taxonomic Profiling, OTU Tables and Visualisation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./denovo-assembly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title"><em>De novo</em> Genome Assembly</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./authentication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Authentication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contamination.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Contamination</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./section-ancient-genomics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancient Genomics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genome-mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Genome Mapping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./phylogenomics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Phylogenomics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./section-ancient-metagenomic-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ancient Metagenomic Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./accessing-ancient-metagenomic-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Accessing Ancient Metagenomic Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ancient-metagenomic-pipelines.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Ancient Metagenomic Pipelines</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./deprecated-chapters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deprecated Chapters</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./functional-profiling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Functional Profiling</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./appendices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-writing-guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Chapter Writing Guidelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-template.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Chapter Page Template</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-checklist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Chapter Checklist</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">17.1</span> Introduction</a></li>
  <li><a href="#workflow-managers" id="toc-workflow-managers" class="nav-link" data-scroll-target="#workflow-managers"><span class="header-section-number">17.2</span> Workflow managers</a></li>
  <li><a href="#what-is-nf-coreeager" id="toc-what-is-nf-coreeager" class="nav-link" data-scroll-target="#what-is-nf-coreeager"><span class="header-section-number">17.3</span> What is nf-core/eager?</a>
  <ul class="collapse">
  <li><a href="#running-nf-coreeager" id="toc-running-nf-coreeager" class="nav-link" data-scroll-target="#running-nf-coreeager"><span class="header-section-number">17.3.1</span> Running nf-core/eager</a></li>
  <li><a href="#top-tips-for-nf-coreeager-success" id="toc-top-tips-for-nf-coreeager-success" class="nav-link" data-scroll-target="#top-tips-for-nf-coreeager-success"><span class="header-section-number">17.3.2</span> Top Tips for nf-core/eager success</a></li>
  <li><a href="#nf-coreeager-output-results-files" id="toc-nf-coreeager-output-results-files" class="nav-link" data-scroll-target="#nf-coreeager-output-results-files"><span class="header-section-number">17.3.3</span> nf-core/eager output: results files</a></li>
  <li><a href="#nf-coreeager-output-run-report" id="toc-nf-coreeager-output-run-report" class="nav-link" data-scroll-target="#nf-coreeager-output-run-report"><span class="header-section-number">17.3.4</span> nf-core/eager output: run report</a></li>
  <li><a href="#clean-up" id="toc-clean-up" class="nav-link" data-scroll-target="#clean-up"><span class="header-section-number">17.3.5</span> Clean up</a></li>
  </ul></li>
  <li><a href="#what-is-ameta" id="toc-what-is-ameta" class="nav-link" data-scroll-target="#what-is-ameta"><span class="header-section-number">17.4</span> What is aMeta?</a>
  <ul class="collapse">
  <li><a href="#running-ameta" id="toc-running-ameta" class="nav-link" data-scroll-target="#running-ameta"><span class="header-section-number">17.4.1</span> Running aMeta</a></li>
  <li><a href="#ameta-configuration" id="toc-ameta-configuration" class="nav-link" data-scroll-target="#ameta-configuration"><span class="header-section-number">17.4.2</span> aMeta configuration</a></li>
  <li><a href="#prepare-and-run-ameta" id="toc-prepare-and-run-ameta" class="nav-link" data-scroll-target="#prepare-and-run-ameta"><span class="header-section-number">17.4.3</span> Prepare and run aMeta</a></li>
  <li><a href="#ameta-output" id="toc-ameta-output" class="nav-link" data-scroll-target="#ameta-output"><span class="header-section-number">17.4.4</span> aMeta output</a></li>
  <li><a href="#clean-up-1" id="toc-clean-up-1" class="nav-link" data-scroll-target="#clean-up-1"><span class="header-section-number">17.4.5</span> Clean up</a></li>
  </ul></li>
  <li><a href="#what-is-nf-coremag" id="toc-what-is-nf-coremag" class="nav-link" data-scroll-target="#what-is-nf-coremag"><span class="header-section-number">17.5</span> What is nf-core/mag?</a>
  <ul class="collapse">
  <li><a href="#running-nf-coremag" id="toc-running-nf-coremag" class="nav-link" data-scroll-target="#running-nf-coremag"><span class="header-section-number">17.5.1</span> Running nf-core/mag</a></li>
  <li><a href="#configuring-nextflow-pipelines" id="toc-configuring-nextflow-pipelines" class="nav-link" data-scroll-target="#configuring-nextflow-pipelines"><span class="header-section-number">17.5.2</span> Configuring Nextflow pipelines</a></li>
  <li><a href="#nf-coremag-output-results-files" id="toc-nf-coremag-output-results-files" class="nav-link" data-scroll-target="#nf-coremag-output-results-files"><span class="header-section-number">17.5.3</span> nf-core/mag output: results files</a></li>
  <li><a href="#nf-coremag-output-run-report" id="toc-nf-coremag-output-run-report" class="nav-link" data-scroll-target="#nf-coremag-output-run-report"><span class="header-section-number">17.5.4</span> nf-core/mag output: run report</a></li>
  </ul></li>
  <li><a href="#optional-clean-up" id="toc-optional-clean-up" class="nav-link" data-scroll-target="#optional-clean-up"><span class="header-section-number">17.6</span> (Optional) clean-up</a></li>
  <li><a href="#questions-to-think-about" id="toc-questions-to-think-about" class="nav-link" data-scroll-target="#questions-to-think-about"><span class="header-section-number">17.7</span> Questions to think about</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">17.8</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./section-ancient-metagenomic-resources.html">Ancient Metagenomic Resources</a></li><li class="breadcrumb-item"><a href="./ancient-metagenomic-pipelines.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Ancient Metagenomic Pipelines</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Ancient Metagenomic Pipelines</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>James A. Fellows Yates, Megan Michel, Nikolay Oskolkov </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled" title="Self guided: chapter environment setup">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Self guided: chapter environment setup
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For this chapter’s exercises, if not already performed, we will need to download the chapter’s dataset, decompress the archive, and create and activate the conda environment.</p>
<p>Do this, use <code>wget</code> or right click and save to download this Zenodo archive: <a href="https://doi.org/10.5281/zenodo.13759201">10.5281/zenodo.13759201</a>, and unpack.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tar</span> xvf ancient-metagenomic-pipelines.tar.gz </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ancient-metagenomic-pipelines/</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then create the subsequently activate environment with the following commands.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> env create <span class="at">-f</span> ancient-metagenomic-pipelines.yml</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate ancient-metagenomic-pipelines</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are additional software requirements for this chapter</p>
<p>Please see the relevant chapter section in <a href="./before-you-start.html">Before we start</a> before continuing with this chapter.</p>
</div>
</div>
<section id="introduction" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">17.1</span> Introduction</h2>
<p>A <strong>pipeline</strong> is a series of linked computational steps, where the output of one process becomes the input of the next. Pipelines are critical for managing the huge quantities of data that are now being generated regularly as part of ancient DNA analyses. In this chapter we will go through three dedicated ancient DNA pipelines - all with some (or all!) functionality geared to ancient metagenomics - to show we how we can speed up the more routine aspects of the basic analyses we’ve learnt about earlier in this text book through workflow automation.</p>
<p>We will introduce:</p>
<ul>
<li><strong>nf-core/eager</strong> (<a href="https://nf-co.re/eager">https://nf-co.re/eager</a>) - a generalised aDNA ‘workhorse’ pipeline that can do both ancient genomics and (basic) metagenomics <span class="citation" data-cites="Fellows_Yates2021-jl">(<a href="#ref-Fellows_Yates2021-jl" role="doc-biblioref">Fellows Yates et al. 2021</a>)</span></li>
<li><strong>aMeta</strong> (<a href="https://github.com/NBISweden/aMeta">https://github.com/NBISweden/aMeta</a>) - a pipeline for resource efficient and accurate ancient microbial detection and authentication <span class="citation" data-cites="Pochon2022-hj">(<a href="#ref-Pochon2022-hj" role="doc-biblioref">Pochon et al. 2022</a>)</span></li>
<li><strong>nf-core/mag</strong> (<a href="https://nf-co.re/mag">https://nf-co.re/mag</a>) - a <em>de novo</em> metagenomics assembly pipeline <span class="citation" data-cites="Krakau2022-we">(<a href="#ref-Krakau2022-we" role="doc-biblioref">Krakau et al. 2022</a>)</span> that includes a dedicated ancient DNA mode for damage correction and validation.</li>
</ul>
<p>Keep in mind that that there are many other pipelines that exist, and picking which one often they come down to personal preference, such as which functionality they support, which language they are written in, and whether their computational requirements can fit in our available resources.</p>
<p>Other examples of other ancient DNA genomic pipelines include <strong>Paleomix</strong> <span class="citation" data-cites="Schubert2014-ps">(<a href="https://paleomix.readthedocs.io/en/stable">https://paleomix.readthedocs.io/en/stable</a>, <a href="#ref-Schubert2014-ps" role="doc-biblioref">Schubert et al. 2014</a>)</span>, and <strong>Mapache</strong> <span class="citation" data-cites="Neuenschwander2023-aj">(<a href="https://github.com/sneuensc/mapache">https://github.com/sneuensc/mapache</a>, <a href="#ref-Neuenschwander2023-aj" role="doc-biblioref">Neuenschwander et al. 2023</a>)</span>, and for ancient metagenomics: <strong>metaBit</strong> <span class="citation" data-cites="Louvel2016-jo">(<a href="https://bitbucket.org/Glouvel/metabit/src/master/">https://bitbucket.org/Glouvel/metabit/src/master/</a>, <a href="#ref-Louvel2016-jo" role="doc-biblioref">Louvel et al. 2016</a>)</span> and <strong>HAYSTAC</strong> <span class="citation" data-cites="Dimopoulos2022-tp">(<a href="https://github.com/antonisdim/haystac">https://github.com/antonisdim/haystac</a>, <a href="#ref-Dimopoulos2022-tp" role="doc-biblioref">Dimopoulos et al. 2022</a>)</span>.</p>
</section>
<section id="workflow-managers" class="level2" data-number="17.2">
<h2 data-number="17.2" class="anchored" data-anchor-id="workflow-managers"><span class="header-section-number">17.2</span> Workflow managers</h2>
<p>All the pipelines introduced in this chapter utilise <em>workflow managers</em>. These are software that allows users to ‘chain’ together the inputs and outputs distinct ‘atomic’ steps of a bioinformatics analysis - e.g., separate terminal commands of different bioinformatic tools, so that ‘we don’t have to’. we have already seen very basic workflows or ‘pipelines’ when using the bash ‘pipe’ (<code>|</code>) in the <a href="./bare-bones-bash.html">Introduction to the Command Line</a> chapter, where the each row of text the output of one command was ‘streamed’ into the next command.</p>
<p>However in the case of bioinformatics, we are often dealing with non-row based text files, meaning that ‘classic’ command line pipelines don’t really work. Instead this is where bioinformatic <em>workflow managers</em> come in: they handle the passing of files from one tool to the next but in a <em>reproducible</em> manager.</p>
<p>Modern computational bioinformatic workflow managers focus on a few main concepts. To summarise <span class="citation" data-cites="Wratten2021-es">Wratten, Wilm, and Göke (<a href="#ref-Wratten2021-es" role="doc-biblioref">2021</a>)</span>, these areas are: data provenance, portability, scalability, re-entrancy - all together which contribute to ensuring reproducibility of bioinformatic analyses.</p>
<p><strong>Data provenance</strong> refers to the ability to track and visualise where each file goes and gets processed, as well as <em>metadata</em> about each file and process (e.g., What version of a tool was used? What parameters were used in that step? How much computing resources were used).</p>
<p><strong>Portability</strong> follows from data provenance where it’s not just can the entire execution of the pipeline be reconstructed - but can it also be run <em>with the same results</em> on a different machine? This is important to ensure that we can install and test the pipeline on our laptop, but when we then need to do <em>heavy</em> computation using real data, that it will still be able to execute on a high-performance computing cluster (HPC) or on the cloud - both that have very different configurations. This is normally achieved through the use of reusable software environments such as as conda (<a href="https://docs.conda.io/en/latest/">https://docs.conda.io/en/latest/</a>) or container engines such as docker (<a href="https://www.docker.com/">https://www.docker.com/</a>), and tight integration with HPC schedulers such as SLURM (<a href="https://slurm.schedmd.com/documentation.html">https://slurm.schedmd.com/documentation.html</a>).</p>
<p>As mentioned earlier, not having to run each command manually can be a great speed up to our analysis. However this needs to be able to be <strong>Scalable</strong> that it the workflow is still efficient regardless whether we’re running with one or ten thousands samples - modern workflow managers perform resource requirement optimisation and scheduling to ensure that all steps of the pipeline will be executed in the most resource efficient manner so it completes as fast as possible - but regardless of of the number of input data.</p>
<p>Finally, as workflows get bigger and longer, <strong>re-entrancy</strong> has become more important, i.e., the ability to re-start a pipeline run that got stuck halfway through due to an error.</p>
<p>All workflow managers have different ways of implementing the concepts above, and these can be very simple (e.g., <strong>Makefiles</strong>, <a href="https://en.wikipedia.org/wiki/Make_(software)">https://en.wikipedia.org/wiki/Make_(software)</a>)) to very powerful and abstract (e.g.&nbsp;<strong>Workflow Description Language</strong>, <a href="https://github.com/openwdl/wdl">https://github.com/openwdl/wdl</a>). In this chapter we will use pipelines that use two popular workflow managers in bioinformatics, <strong><code>Nextflow</code></strong> (<a href="https://nextflow.io">https://nextflow.io</a>, <span class="citation" data-cites="Di_Tommaso2017-xu">(<a href="#ref-Di_Tommaso2017-xu" role="doc-biblioref">Di Tommaso et al. 2017</a>)</span>) and <strong><code>Snakemake</code></strong> (<a href="https://snakemake.github.io">https://snakemake.github.io</a>, <span class="citation" data-cites="Molder2021-et">(<a href="#ref-Molder2021-et" role="doc-biblioref">Mölder et al. 2021</a>)</span>).</p>
<p>This chapter will not cover how to write our <em>own</em> workflow, as this would require a whole other textbook. However it is recommended to learn and use workflow managers when carrying out repetitive or routine bioinformatic analysis (Nextflow and Snakemake being two popular ones in bioinformatics). Use of workflow managers can help make our work more efficiently (as we only run one command, rather than each step separately), but also more <em>reproducible</em> by reducing the risk of user error when executing each step: the computer will do exactly what we tell it, and if we don’t change anything, will do the exact same thing every time. If you’re interested in writing our own workflows using workflow managers, many training and tutorials exist on the internet (e.g., for <code>Nextflow</code> there is the official training: <a href="https://training.nextflow.io/">https://training.nextflow.io/</a> or from software carpentries: <a href="https://carpentries-incubator.github.io/workflows-nextflow/">https://carpentries-incubator.github.io/workflows-nextflow/</a>, or the official training for snakemake: <a href="https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#tutorial">https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#tutorial</a>).</p>
</section>
<section id="what-is-nf-coreeager" class="level2" data-number="17.3">
<h2 data-number="17.3" class="anchored" data-anchor-id="what-is-nf-coreeager"><span class="header-section-number">17.3</span> What is nf-core/eager?</h2>
<p>nf-core/eager is a computational pipeline specifically designed for preprocessing and analysis of ancient DNA data (<a href="#fig-ancientmetagenomicpipelines-eagermetromap" class="quarto-xref">Figure&nbsp;<span>17.1</span></a>) <span class="citation" data-cites="Fellows_Yates2021-jl">(<a href="#ref-Fellows_Yates2021-jl" role="doc-biblioref">Fellows Yates et al. 2021</a>)</span>. It is a reimplementation of the previously published EAGER (Efficient Ancient Genome Reconstruction) pipeline <span class="citation" data-cites="Peltzer2016-ov">(<a href="#ref-Peltzer2016-ov" role="doc-biblioref">Peltzer et al. 2016</a>)</span> written in the workflow manager <code>Nextflow</code>. In addition to reimplementing the original genome mapping and variant calling pipeline, in a more reproducible and portable manner the pipeline also included additional new functionality particularly for researchers interested in microbial sciences, namely a dedicated genotyper and consensus caller designed for low coverage genomes, the ability to get breadth and depth coverage statistics for particular genomic features (e.g.&nbsp;virulence genes), but also automated metagenomic screening and authentication of the off-target reads from mapping (e.g.&nbsp;against the host reference genome).</p>
<div id="fig-ancientmetagenomicpipelines-eagermetromap" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-eagermetromap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/eager2_metromap_complex.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-eagermetromap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.1: nf-core/eager workflow summary in the form of a ‘metro map’ style diagram. FASTQ or BAM input for red and yellow lines (representing eukaryotic and prokaryotic workflows) goes through <code>FastQC</code>, <code>AdapterRemoval</code>, alignment to a reference FASTA input with a range of alignments, before going through BAM filtering, deduplication, <em>in silico</em> damage removal, and variant calling. Multiple statistics steps come out of the deduplication ‘station’. The blue line represents the metagenomic workflow, where off-target reads come out of the BAM filtering ‘station’, and goes through complexity filtering with <code>BBDuk</code>, <code>MALT</code> or <code>Kraken2</code>, and optionally into <code>MaltExtract</code> for <code>MALT</code> output.
</figcaption>
</figure>
</div>
<p>A detailed description of steps in the pipeline is available as part of nf-core/eager’s extensive documentation. For more information, check out the usage documentation (<a href="https://nf-co.re/eager/2.5.2/docs/usage/">https://nf-co.re/eager/2.5.2/docs/usage/</a>).</p>
<p>Briefly, nf-core/eager takes at a minimum standard input file types that are shared across the genomics field, i.e., raw FASTQ files or aligned reads in bam format, and a reference fasta. nf-core/eager performs preprocessing of this raw data, including adapter clipping, read merging, and quality control of adapter-trimmed data. nf-core/eager then carries mapping using a variety of field-standard shot-read alignment tools with default parameters adapted for short and damaged aDNA sequences. The off-target reads from host DNA mapping can then go into metagenomic classification and authentication (in the case of <code>MALT</code> <span class="citation" data-cites="Vagene2018-px Herbig2016-rq">(<a href="#ref-Vagene2018-px" role="doc-biblioref">Vågene et al. 2018</a>; <a href="#ref-Herbig2016-rq" role="doc-biblioref">Herbig et al. 2016</a>)</span>). After genomic mapping, BAM files go through deduplication of PCR duplicates, damage profiling and removal, and finally variant calling. A myriad of additional statistics can be generated depending on the users preference. Finally, nf-core eager uses <code>MultiQC</code> (<a href="https://multiqc.info/">https://multiqc.info/</a>, <span class="citation" data-cites="Ewels2016-mv">(<a href="#ref-Ewels2016-mv" role="doc-biblioref">Ewels et al. 2016</a>)</span>) to create an integrated html report that summarises the output/results from each of the pipeline steps.</p>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why cannot we use a standard genomics mapping and variant calling pipeline, such as nf-core/sarek <span class="citation" data-cites="Garcia2020-wq">Hanssen et al. (<a href="#ref-Hanssen2024-ul" role="doc-biblioref">2024</a>)</span> for ancient DNA ?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Many tools used in standard genomics pipelines assume ‘modern’ data quality, i.e., high coverage, low error rates, and long read lengths.</p>
<p>In ancient DNA we need to use tools better suited for low coverage, and short read lengths. Furthermore, we would like additional tools for authenticating our ancient DNA - characteristics that you would not expect to find in modern data and thus not included in modern pipelines.</p>
</div>
</div>
</div>
<section id="running-nf-coreeager" class="level3" data-number="17.3.1">
<h3 data-number="17.3.1" class="anchored" data-anchor-id="running-nf-coreeager"><span class="header-section-number">17.3.1</span> Running nf-core/eager</h3>
<p>For the practical portion of this chapter, we will utilise sequencing data from four aDNA libraries, which we should have already downloaded from NCBI. If not, please see the <strong>Preparation</strong> section above <!-- TODO Add download links & DOWNLOAD GFF FILE - SEE NOTE BELOW -->. We will use nf-core/eager to perform a typical microbial <em>genomic</em> analysis, i.e., reconstruction of an ancient genome to generate variant calls that can be used for generating phylogenomic trees and other evolutionary analysis, and gene feature coverage statistics to allow insight into the functional aspects of the genome.</p>
<p>These four libraries come from from two ancient individuals, GLZ002 and KZL002. GLZ002 comes from the Neolithic Siberian site of Glazkovskoe predmestie <span class="citation" data-cites="Yu2020-zw">(<a href="#ref-Yu2020-zw" role="doc-biblioref">Yu et al. 2020</a>)</span> and was radiocarbon dated to 3081-2913 calBCE. KZL002 is an Iron Age individual from Kazakhstan, radiocarbon dated to 2736-2457 calBCE <span class="citation" data-cites="Andrades_Valtuena2022-tq">(<a href="#ref-Andrades_Valtuena2022-tq" role="doc-biblioref">Andrades Valtueña et al. 2022</a>)</span>. Both individuals were originally analysed for human population genetic analysis, but when undergoing metagenomic screening of the off-target reads, both set of authors identified reads from <em>Yersinia pestis</em> from these individuals - the bacterium that causes plague. Subsequently the libraries from these individuals were processed using hybridisation capture to increase the number of <em>Y. pestis</em> sequences available for analysis.</p>
<p>Our aims in the following tutorial are to:</p>
<ol type="1">
<li>Preprocess the FASTQ files by trimming adapters and merging paired-end reads</li>
<li>Align reads to the <em>Y. pestis</em> reference and compute the endogenous DNA percentage</li>
<li>Filter the aligned reads to remove host DNA</li>
<li>Remove duplicate reads for accurate coverage estimation and genotyping</li>
<li>Generate statistics on gene features (e.g.&nbsp;virulence factors)</li>
<li>Merge data by sample and perform genotyping on the combined dataset</li>
<li>Review quality control data to evaluate the success of the previous steps</li>
</ol>
<p>Let’s get started!</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>nf-core/eager v2 requires an older version of <code>Nextflow</code> - if installing manually, ensure we do not have <code>Nextflow</code> version any greater than v22.10.6!</p>
</div>
</div>
<p>First, download the latest version of the nf-core/eager repo (or check for updates if we have a previously-installed version).</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">nextflow</span> pull nf-core/eager</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Next we can re-visit AMDirT (see <a href="./accessing-ancient-metagenomic-data.html">Accessing Ancient Metagenomic Data</a>, <span class="citation" data-cites="Borry2024-dz">(<a href="#ref-Borry2024-dz" role="doc-biblioref">Borry et al. 2024</a>)</span>) to download a pre-prepared configuration file for nf-core/eager</p>
<ol type="1">
<li>Load AMDirt (<code>AMDirT viewer</code>), and select the latest release and the ‘ancientsinglegenome-hostassociated’ table</li>
<li>Filter the <code>sample_name</code> column to just show KZL002 and GLZ002, and select these two rows
<ul>
<li>Press the burger icon on the column</li>
<li>Press the filter tab and deselect everything</li>
<li>Search <em>GLZ002</em> and select in filter menu</li>
<li>Search <em>KZL002</em> and select in filter menu (careful: <em>K<strong>Z</strong>L</em> not <em>K<strong>L</strong>Z</em>!)</li>
<li>Close filter menu and select the two rows</li>
</ul></li>
<li>Press the Validate Selection button</li>
<li>Press the ‘Download Curl sample download script’, ‘Download nf-core/eager input TSV’, and ‘Download Citations as BibTex’ buttons</li>
<li>Move the downloaded files into <code>eager/</code> of this tutorial’s directory
<ul>
<li>i.e., if the files were downloaded to we <code>Downloads/</code> folder rather than the chapters directory,</li>
<li>e.g., assuming we’ve got no other previous downloads we can run <code>mv ~/Downloads/AncientMetagenomeDir_* eager/</code></li>
</ul></li>
<li>Close AMDiRT in the web browser and shut it down in the terminal with <kdb>ctrl + <kbd>c</kbd></kdb></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>We won’t actually use the BibTex citations file for anything in this tutorial, but it is good habit to <em>always</em> to record and save all citations of any software or data we use!</p>
</div>
</div>
<p>To download the FASTQ files</p>
<ol type="1">
<li>Move into the <code>eager/</code> directory</li>
<li>Run <code>bash AncientMetagenomeDir_curl_download_script.sh</code> to download the files (this may take ~3 minutes)</li>
</ol>
<p>Next we now inspect the AMDirT generated input TSV file for nf-core/eager!</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> AncientMetagenomeDir_nf_core_eager_input_table.tsv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Sample_Name Library_ID  Lane    Colour_Chemistry    SeqType Organism    Strandedness    UDG_Treatment   R1  R2  BAM
GLZ002  ERR4093961  0   4   PE  Homo sapiens    double  half    ERR4093961_1.fastq.gz   ERR4093961_2.fastq.gz   NA
GLZ002  ERR4093962  0   4   PE  Homo sapiens    double  full    ERR4093962_1.fastq.gz   ERR4093962_2.fastq.gz   NA
KZL002  ERR8958768  0   4   PE  Homo sapiens    double  half    ERR8958768_1.fastq.gz   ERR8958768_2.fastq.gz   NA
KZL002  ERR8958769  0   4   PE  Homo sapiens    double  half    ERR8958769_1.fastq.gz   ERR8958769_2.fastq.gz   NA</code></pre>
<p>Here we see 10 columns, all pre-filled. The first two columns correspond to sample/library IDs that will be used for data provenance and grouping. When we have sequencing multiple lanes we can speed up preprocessing these independently before merging, so lane can specify this (although not used in this case as we have independent libraries per sample. we can indicate the colour chemistry to indicate whether our data requires additional pre-processing to remove poly-G tails, and then also strandedness and UDG damage treatment status of the libraries if we require further damage manipulation. Finally we provide paths to the FASTQ files or BAM files.</p>
<p>Other than the raw FASTQ files, we will need a reference genome and annotation coordinates of genes present on the genome. In this case we will use a <em>Yersinia pestis</em> (accession: GCF_001293415.1) reference genome (<code>.fna</code>) and gene feature file (<code>.gff</code>) from NCBI Genome (<a href="https://www.ncbi.nlm.nih.gov/genome">https://www.ncbi.nlm.nih.gov/genome</a>).</p>
<p>These have already been placed in the <code>reference/</code> directory for us.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Self guided: reference download and preparation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Self guided: reference download and preparation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To download the required reference genome and annotation file run the following command to download from the NCBI Genome database.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Download from NCBI</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> <span class="at">-OJX</span> GET <span class="st">"https://api.ncbi.nlm.nih.gov/datasets/v2alpha/genome/accession/GCF_001293415.1/download?include_annotation_type=GENOME_FASTA,GENOME_GFF,RNA_FASTA,CDS_FASTA,PROT_FASTA,SEQUENCE_REPORT&amp;filename=GCF_001293415.1.zip"</span> <span class="at">-H</span> <span class="st">"Accept: application/zip"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">unzip</span> <span class="pp">*</span>.zip</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mv</span> ncbi_dataset/data/GCF_001293415.1/<span class="pp">*</span> .</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">## We have to sort the gff file to make it eager compatible</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="ex">gffread</span> genomic.gff GCF_001293415.1_ASM129341v1_genomic.gff</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>With all of these, we can run the pipeline!</p>
<p>First lets enter a screen session to make sure we can leave the pipeline running in the background and continue using our terminal.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">screen</span> <span class="at">-R</span> eager</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate ancient-metagenomic-pipelines</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we can construct an eager command from within the <code>data/</code> directory so that it looks like this.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">nextflow</span> run nf-core/eager <span class="at">-r</span> 2.5.3 <span class="dt">\</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>-profile docker <span class="dt">\</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>--fasta ../reference/GCF_001293415.1_ASM129341v1_genomic.fna <span class="dt">\</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>--input AncientMetagenomeDir_nf_core_eager_input_table.tsv <span class="dt">\</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>--anno_file ../reference/GCF_001293415.1_ASM129341v1_genomic.gff <span class="dt">\</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>--run_bam_filtering <span class="at">--bam_unmapped_type</span> discard <span class="dt">\</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>--skip_preseq <span class="dt">\</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>--run_genotyping <span class="at">--genotyping_tool</span> ug <span class="at">--gatk_ug_out_mode</span> EMIT_ALL_SITES <span class="dt">\</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>--run_bcftools_stats <span class="at">--run_bedtools_coverage</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>When the run starts, we see a long list of <code>process</code> lines with progress bars slowly appearing over time. If we press <kbd>ctrl</kbd> + <kbd>a</kbd> and then <kbd>[</kbd> to access a ‘navigation’ (called ‘copy’) mode, then use our arrow keys on our keyboard to scroll up and down. To quit this mode just press <code>q</code>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>We don’t normally recommend running analyses in the directory our data is in! It is better to keep data and analysis results in separate directories. Here we are just running eager alongside the data for convenience (i.e., we don’t have to modify the downloaded input TSV)</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This run will take between 20m-40m to run on a standard laptop! Time for a break, or we can continue reading this chapter as the critical output data has already been provided for we in the data directory.</p>
</div>
</div>
<p>So what is this command doing? The different parameters do the following:</p>
<ol type="1">
<li>Tell <code>nextflow</code> to run the nf-core/eager pipeline with version 2.4.7</li>
<li>Specify which computing and software environment to use with <code>-profile</code>
<ul>
<li>In this case we are running locally so we don’t specify a computing environment (such as a configuration for an institutional HPC)</li>
<li>We use <code>docker</code> as our container engine, which downloads all the software and specific versions needed for nf-core/eager in immutable ‘containers’, to ensure nothing get broken and is as nf-core/eager expects</li>
</ul></li>
<li>Provide the various paths to the input files (TSV with paths to FASTQ files, a reference fasta, and the reference fasta’s annotations)</li>
<li>Activate the various of the steps of the pipeline we’re interested in
<ul>
<li>We turn off preseq (e.g.&nbsp;when we know we can’t sequence more)</li>
<li>We want to turn on BAM filtering, and specify to generate unmapped reads in FASTQ file (so we could check off target reads e.g.&nbsp;for other pathogens)</li>
<li>we turn on genotyping using <code>GATK UnifiedGenotyper</code> (preferred over <code>GATK HaplotypeCaller</code> <span class="citation" data-cites="Poplin2018-yq">(<a href="#ref-Poplin2018-yq" role="doc-biblioref">Poplin et al. 2018</a>)</span> due to in compatibility with that method to low-coverage data)</li>
<li>We turn on variant statistics (from GATK) using <code>bcftools</code> <span class="citation" data-cites="Danecek2021-gj">(<a href="#ref-Danecek2021-gj" role="doc-biblioref">Danecek et al. 2021</a>)</span>, and coverage statistics of gene features using bedtools <span class="citation" data-cites="Quinlan2010-lf">(<a href="#ref-Quinlan2010-lf" role="doc-biblioref">Quinlan and Hall 2010</a>)</span></li>
</ul></li>
</ol>
<p>For full parameter documentation, see the website (<a href="https://nf-co.re/eager/2.5.2/parameters">https://nf-co.re/eager/2.5.2/parameters</a>).</p>
<p>And now we wait… <!-- TODO 40m on DENBI Node! Can we shorten? Maybe use Virus data from Muhlemann2020? --></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>As a reminder, to detach from the screen session type <kbd>ctrl</kbd> + <kbd>a</kbd> then <kbd>d</kbd>. To reattach <code>screen -r eager</code></p>
</div>
</div>
<p>Specifically for ancient (meta)genomic data, the following parameters and options may be useful to consider when running our own data:</p>
<ul>
<li><code>--mapper circularmapper</code>
<ul>
<li>This aligner is a variant of <code>bwa aln</code> that allows even mapping across the end of linear references of circular genomes</li>
<li>Allows reads spanning the start/end of the sequence to be correctly placed, and this provides better coverage estimates across the entire genome</li>
</ul></li>
<li><code>--hostremoval_input_fastq</code>:
<ul>
<li>Allows re-generation of input FASTQ files but with any reads aligned to the reference genome removed</li>
<li>Can be useful when dealing with modern or ancient data where there are ethical restrictions on the publication of host DNA</li>
<li>The output can be used as ‘raw data’ upload to public data repositories</li>
</ul></li>
<li><code>--run_bam_filtering --bam_unmapped_type</code>
<ul>
<li>A pre-requisite for performing the metagenomic analysis steps of nf-core/eager</li>
<li>Generates FASTQ files off the unmapped reads present in the reference mapping BAM file</li>
</ul></li>
<li><code>--run_bedtools_coverage --anno_file /&lt;path&gt;/&lt;to&gt;/&lt;genefeature&gt;.bed</code>
<ul>
<li>Turns on calculating depth/breadth of annotations in the provided bed or GFF file, useful for generating e.g.&nbsp;virulence gene presence/absence plots</li>
</ul></li>
<li><code>--run_genotyping --genotyping_tool ug --gatk_ug_out_mode EMIT_ALL_SITES</code>
<ul>
<li>Turns on genotyping with <code>GATK UnifiedGenotyper</code></li>
<li>A pre-requisite for running <code>MultiVCFAnalyzer</code> <span class="citation" data-cites="Bos2014-xe">(<a href="#ref-Bos2014-xe" role="doc-biblioref">Bos et al. 2014</a>)</span> for consensus sequencing creation</li>
<li>It’s recommend to use either <code>GATK UnifiedGenotyper</code> or <code>freeBayes</code> <span class="citation" data-cites="Garrison2012-pv">(non-MultiVCFAnalyzer compatible!, <a href="#ref-Garrison2012-pv" role="doc-biblioref">Garrison and Marth 2012</a>)</span> for low-coverage data</li>
<li><code>GATK HaplotypeCaller</code> is <em>not</em> recommended for low coverage data as it performs local <em>de novo</em> assembly around possible variant sites, and this will fail with low-coverage short-read data</li>
</ul></li>
<li><code>--run_multivcfanalyzer --write_allele_frequencies</code>
<ul>
<li>Turns on SNP table and FASTA consensus sequence generation with <code>MultiVCFAnalyzer</code> (see pre-requisites above)</li>
<li>By providing <code>--write_allele_frequencies</code>, the SNP table will also provide the percentage of reads at that position supporting the call. This can help we evaluate the level of cross-mapping from related (e.g.&nbsp;contaminating environmental) species and may question the reliability of any resulting downstream analyses.</li>
</ul></li>
<li><code>--metagenomic_complexity_filtering</code>
<ul>
<li>An additional preprocessing step of raw reads before going into metagenomic screening to remove low-complexity reads (e.g.&nbsp;mono- or di-nucleotide repeats)</li>
<li>Removing these will speed up and lower computational requirements during classification, and will not bias profiles as these sequences provide no taxon-specific information (i.e., can be aligned against thousands to millions of genomes)</li>
</ul></li>
<li><code>--run_metagenomic_screening</code>
<ul>
<li>Turns on metagenomic screening with either <code>MALT</code> or <code>Kraken2</code></li>
<li>If running with <code>MALT</code>, can supply <code>--run_maltextract</code> to get authentication statistics and plots (damage, read lengths etc.) for evaluation</li>
</ul></li>
</ul>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is it critical to report versions of all pipelines and tools?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>(Bioinformatics) software is rarely stable.</p>
<p>Many tools will update frequently either with bug fixes and new or optimised functionality.</p>
<p>Both can cause changes in the output of the software, and thus the results of our analyses. If we want our analyses to be completely reproducible, and increase trust of other scientists in our results, we need to make sure they can generate the same output as we did.</p>
</div>
</div>
</div>
</section>
<section id="top-tips-for-nf-coreeager-success" class="level3" data-number="17.3.2">
<h3 data-number="17.3.2" class="anchored" data-anchor-id="top-tips-for-nf-coreeager-success"><span class="header-section-number">17.3.2</span> Top Tips for nf-core/eager success</h3>
<ol type="1">
<li><p>Screen sessions</p>
<p>Depending on the size of our input data, infrastructure, and analyses, running nf-core/eager can take hours or even days (e.g.&nbsp;the example command above will likely take around 20 minutes!).</p>
<p>To avoid crashes due to loss of power or network connectivity, try running nf-core/eager in a <code>screen</code> or <code>tmux</code> session.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">screen</span> <span class="at">-R</span> eager</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Multiple ways to supply input data</p>
<p>In this tutorial, a tsv file to specify our input data files and formats. This is a powerful approach that allows nf-core eager to intelligently apply analyses to certain files only (e.g.&nbsp;merging for paired-end but not single-end libraries). However inputs can also be specified using wildcards, which can be useful for fast analyses with simple input data types (e.g.&nbsp;same sequencing configuration, file location, etc.).</p>
<p>See the online nf-core/eager documentation (<a href="https://nf-co.re/eager/usage">https://nf-co.re/eager/usage</a>) for more details.</p></li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled" title="Example commands - do not run!">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example commands - do not run!
</div>
</div>
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">nextflow</span> run nf-core/eager <span class="at">-r</span> 2.4.7 <span class="at">-profile</span> docker <span class="at">--fasta</span> ../reference/GCF_001293415.1_ASM129341v1_genomic.fna <span class="dt">\</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>--input <span class="st">"data/*_{1,2}.fastq.gz"</span> <span class="op">&lt;</span>...<span class="op">&gt;</span> <span class="dt">\</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>--udg_type half</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<ol start="3" type="1">
<li><p>Get our <code>MultiQC</code> report via email</p>
<p>If we have <code>GNU mail</code> or <code>sendmail</code> set up on our system, we can add the following flag to send the <code>MultiQC</code> html to our email upon run completion:</p>
<p><code>--email "your_address@something.com"</code></p></li>
<li><p>Check out the nf-core/eager launch GUI</p>
<p>For researchers who might be less comfortable with the command line, check out the nf-core/eager launch GUI (<a href="https://nf-co.re/launch?pipeline=eager&amp;release=2.5.2">https://nf-co.re/launch?pipeline=eager&amp;release=2.5.2</a>)! The GUI also provides a full list of all pipeline options with short explanations for those interested in learning more about what the pipeline can do.</p></li>
<li><p>When something fails, all is not lost!</p>
<p>When individual jobs fail, nf-core/eager will <em>try</em> to automatically resubmit that job with increased memory and CPUs (up to two times per job).</p>
<p>When the whole pipeline crashes, we can save time and computational resources by resubmitting with the <code>-resume</code> flag. nf-core/eager will retrieve cached results from previous steps as long as the input is the same.</p></li>
<li><p>Monitor our pipeline in real time with the Seqera Platform</p>
<p>Regular users may be interested in checking out the Seqera Platform (previously known as Nextflow Tower), a tool for monitoring the progress of <code>Nextflow</code> pipelines in real time. Check the website (<a href="https://tower.nf">https://tower.nf</a>) for more information.</p></li>
</ol>
</section>
<section id="nf-coreeager-output-results-files" class="level3" data-number="17.3.3">
<h3 data-number="17.3.3" class="anchored" data-anchor-id="nf-coreeager-output-results-files"><span class="header-section-number">17.3.3</span> nf-core/eager output: results files</h3>
<p>Once completed, the <code>results/</code> directory of our nf-core/eager run will contain a range of directories that will have output files and tool logs of all the steps of the pipeline. nf-core/eager tries to only save the ‘useful’ files.</p>
<p>Everyday useful files for ancient (microbial) (meta)genomics typically are in folders such as:</p>
<ul>
<li><code>deduplication/</code> or <code>merged_bams/</code>
<ul>
<li>These contain the most basic BAM files we would want to use for downstream analyses (and used in the rest of the genomic workflow of the pipeline)</li>
<li>They contain deduplicated BAM files (i.e., with PCR artefacts removed)</li>
<li><code>merged_bams/</code>
<ul>
<li>This directory will contain BAMs where multiple libraries of one sample have been merged into one final BAM file, when these have been supplied</li>
</ul></li>
</ul></li>
<li><code>damage_rescaling/</code> or <code>trimmed bam/</code>
<ul>
<li>These contain the output BAM files from <em>in silico</em> damage removal, if we have turned on e.g.&nbsp;BAM trimming or damage rescaling</li>
<li>If we have multiple libraries of one sample, the final BAMs we want will be in <code>merged_bams/</code></li>
</ul></li>
<li><code>genotyping/</code>
<ul>
<li>This directory will contain our final VCF files from the genotyping step, e.g.&nbsp;from the GATK or <code>freeBayes</code> tools</li>
</ul></li>
<li><code>MultiVCFAnalyzer/</code>
<ul>
<li>This will contain consensus sequences and SNP tables from <code>MultiVCFAnalyzer</code>, which also allows generation of ‘multi-allelic’ SNP position statistics (useful for the evaluation of cross-mapping from contaminants or relatives)</li>
</ul></li>
<li><code>bedtools/</code>
<ul>
<li>This directory will contain the depth and breadth statistics of genomic features if a <code>gff</code> or <code>bed</code> file has been provided to the pipeline</li>
<li>The files can be used to generate gene heatmaps, that can be used to visualise a comparative presence/absence of virulence factor across genomes (e.g.&nbsp;for microbial pathogens)</li>
</ul></li>
<li><code>metagenomic_classification</code> or <code>malt_extract</code>
<ul>
<li>This directory contains the output RMA6 files from <code>MALT</code>, the profiles and taxon count tables from <code>Kraken2</code>, or the aDNA authentication output statistics from <code>maltExtract</code>.</li>
</ul></li>
</ul>
<p>Most other folders contain either intermediate files that are only useful for technical evaluation in the case of problems, or statistics files that are otherwise summarised in the run report.</p>
<p>So, before we delve into these folders, it’s normally a good idea to do a ‘quality check’ of the pipeline run. we can do this using the interactive <code>MultiQC</code> pipeline run report.</p>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is it important to use deduplicated BAMs for downstream <em>genomic</em> analyses?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Without deduplication, you are artificially increasing the confidence in variant calls during genotyping. Many downstream analyses assume that each base call is made up of multiple indepndent ‘observations’ of that particular nucleotide. If you have not deduplicated your alignments, you may have the exact sample molecule represented <em>twice</em> (an artefact of amplification), thus violating the ‘independent observation’ assumption.</p>
</div>
</div>
</div>
</section>
<section id="nf-coreeager-output-run-report" class="level3" data-number="17.3.4">
<h3 data-number="17.3.4" class="anchored" data-anchor-id="nf-coreeager-output-run-report"><span class="header-section-number">17.3.4</span> nf-core/eager output: run report</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> multiqc/</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If we’re impatient, and our nf-core/eager run hasn’t finished yet, we can cancel the run with <kbd>ctrl</kbd> + <kbd>c</kbd> (possibly a couple of times), and we can open a pre-made file in the data directory under <code>ancient-metagenomic-pipelines/multiqc_report.html</code></p>
</div>
</div>
<p>In here we should see a bunch of files, but we should open the <code>multiqc_report.html</code> file in our browser. We can either do this via the command-line (e.g.&nbsp;for firefox <code>firefox multiqc_report.html</code>) or navigate to the file using our file browser and double clicking on the HTML file.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>During the summer school if you cannot open the MultiQC HTML file directly in the VM, copy the file to your Downloads folder and open from there.e.g.</p>
<p>For example the following two commands.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cp</span> multiqc_report.html ~/Downloads/</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="ex">firefox</span> ~/Downloads/multiqc_report.html</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Once opened we will see a table, and below it many figures and other tables (<a href="#fig-ancientmetagenomicpipelines-multiqcscreenshot" class="quarto-xref">Figure&nbsp;<span>17.2</span></a>). All of these statistics can help we evaluate the quality of our data, pipeline run, and also possibly some initial results!</p>
<div id="fig-ancientmetagenomicpipelines-multiqcscreenshot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-multiqcscreenshot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/multiqc-screenshot.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-multiqcscreenshot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.2: Screenshot of initial view of a <code>MultiQC</code> report. The left hand sidebar provides links to various sections of the report, most of them containing summary images of the outputs of all the different tools. On the main panel we see the MultiQC and nf-core/eager logos, some descriptive information about how the report was generated, and finally the top of the ‘General Statistics’ tables, that has columns such as Sample Name, Nr. Input reads, length of input reads, %trimmed, etc. Each numeric column contains a coloured bar chart to help readers to quickly evaluate the number of a given sample against all others in the table
</figcaption>
</figure>
</div>
<p>Typically we will look at the General Statistics table to get a rough overview of the pipeline run.</p>
<p>If we hover our cursor over the column headers, we can see which tool the column’s numbers came from, however generally the columns go in order of left to right, where the left most columns are from earlier in the pipeline run (e.g.&nbsp;removing adapters), to variant calling statistics (e.g.&nbsp;number of variants called). we can also configure which columns to display using the <code>Configure columns</code> button.</p>
<p>It’s important to note that in <code>MultiQC</code> tables, we may have duplicate rows from the same library or sample. This is due to <code>MultiQC</code> trying to squish in as many statistics from as many steps of the pipeline as possible (for example, statistics on each of a pair of FASTQ files, and then statistics on the single merged and mapped BAM file), so we should play around with the column configuration to help we visualise the best way to initially evaluate our data.</p>
<p>The bulk of the <code>MultiQC</code> report is made up of per-tool summary plots (e.g., barcharts, linecharts etc.). Most of these will be interactive, we can hover over lines and bars to get more specific numbers of each plot. However the visualisations are aimed at helping we identify possible outliers that may represent failed samples or libraries.</p>
<p>Evaluating how good the data is and how well the run went will vary depending on the dataset and the options selected. However the nf-core/eager tutorials (<a href="https://nf-co.re/eager/usage#tutorial---how-to-set-up-nf-coreeager-for-pathogen-genomics">https://nf-co.re/eager/usage#tutorial—how-to-set-up-nf-coreeager-for-pathogen-genomics</a>) have a good overview of questions we can ask from our <code>MultiQC</code> report to see whether our data is good or not. We shamelessly copy these questions here (as the overlap authors of both the the nf-core/eager documentation and this text book is rather high).</p>
<p>Once completed, we can try going through the <code>MultiQC</code> report the command we executed above, and compare against the questions below. Keep in mind we have a sample <em>N</em> of two, so many of the questions in regards to identifying ‘outliers’ may be difficult.</p>
<p>The following questions are by no means comprehensive, but rather represent the ‘typical’ questions the nf-core/eager developers asked of their own data and reports. However they can act as a good framework for thinking critically about our own results.</p>
<p><strong>General Stats Table</strong></p>
<ul>
<li>Do we see the expected number of raw sequencing reads (summed across each set of FASTQ files per library) that was requested for sequencing?</li>
<li>Does the percentage of trimmed reads look normal for aDNA, and do lengths after trimming look short as expected of aDNA?</li>
<li>Does the Endogenous DNA (%) columns look reasonable (high enough to indicate we have received enough coverage for downstream, and/or do we lose an unusually high reads after filtering )</li>
<li>Does ClusterFactor or ‘% Dups’ look high (e.g.&nbsp;&gt;2 or &gt;10% respectively - high values suggesting over-amplified or badly preserved samples i.e.&nbsp;low complexity; note that genome-enrichment libraries may by their nature look higher)</li>
<li>Do we see an increased frequency of C&gt;Ts on the 5’ end of molecules in the mapped reads?</li>
<li>Do median read lengths look relatively low (normally &lt;= 100 bp) indicating typically fragmented aDNA?</li>
<li>Does the % coverage decrease relatively gradually at each depth coverage, and does not drop extremely drastically</li>
<li>Does the Median coverage and percent &gt;3x (or whatever we set) show sufficient coverage for reliable SNP calls and that a good proportion of the genome is covered indicating we have the right reference genome?</li>
<li>Do we see a high proportion of % Hets, indicating many multi-allelic sites (and possibly presence of cross-mapping from other species, that may lead to false positive or less confident SNP calls)?</li>
</ul>
<p><strong>FastQC (pre-AdapterRemoval)</strong></p>
<ul>
<li>Do we see any very early drop off of sequence quality scores suggesting problematic sequencing run?</li>
<li>Do we see outlier GC content distributions?</li>
<li>Do we see high sequence duplication levels?</li>
</ul>
<p><strong>AdapterRemoval</strong></p>
<ul>
<li>Do we see high numbers of singletons or discarded read pairs?</li>
</ul>
<p><strong>FastQC (post-AdapterRemoval)</strong></p>
<ul>
<li>Do we see improved sequence quality scores along the length of reads?</li>
<li>Do we see reduced adapter content levels?</li>
</ul>
<p><strong>Samtools Flagstat (pre/post Filter)</strong></p>
<ul>
<li>Do we see outliers, e.g.&nbsp;with unusually low levels of mapped reads, (indicative of badly preserved samples) that require downstream closer assessment?</li>
</ul>
<p><strong>DeDup/Picard MarkDuplicates</strong></p>
<ul>
<li>Do we see large numbers of duplicates being removed, possibly indicating over-amplified or badly preserved samples?</li>
</ul>
<p><strong>MALT (metagenomics only)</strong></p>
<ul>
<li>Do we have a reasonable level of mappability?
<ul>
<li>Somewhere between 10-30% can be pretty normal for aDNA, whereas e.g.&nbsp;&lt;1% requires careful manual assessment</li>
</ul></li>
<li>Do we have a reasonable taxonomic assignment success?
<ul>
<li>we hope to have a large number of the mapped reads (from the mappability plot) that also have taxonomic assignment</li>
</ul></li>
</ul>
<p><strong>PreSeq (genomics only)</strong></p>
<ul>
<li>Do we see a large drop off of a sample’s curve away from the theoretical complexity? If so, this may indicate it’s not worth performing deeper sequencing as we will get few unique reads (vs.&nbsp;duplicates that are not any more informative than the reads you’ve already sequenced)</li>
</ul>
<p><strong>DamageProfiler (genomics only)</strong></p>
<ul>
<li>Do we see evidence of damage on the microbial DNA (i.e. a % C&gt;T of more than ~5% in the first few nucleotide positions?) ? If not, possibly our mapped reads are deriving from modern contamination</li>
</ul>
<p><strong>QualiMap (genomics only)</strong></p>
<ul>
<li>Do we see a peak of coverage (X) at a good level, e.g.&nbsp;&gt;= 3x, indicating sufficient coverage for reliable SNP calls?</li>
</ul>
<p><strong>MultiVCFAnalyzer (genomics only)</strong></p>
<ul>
<li>Do we have a good number of called SNPs that suggest the samples have genomes with sufficient nucleotide diversity to inform phylogenetic analysis?</li>
<li>Do we have a large number of discarded SNP calls?</li>
<li>Are the % Hets very high indicating possible cross-mapping from off-target organisms that may confounding variant calling?</li>
</ul>
<p>As above evaluating these outputs will vary depending on the data and or pipeline settings, and very much. However the extensive output documentation (<a href="https://nf-co.re/eager/2.4.7/output">https://nf-co.re/eager/2.4.7/output</a>) of nf-core/eager can guide we through every single table and plot to assist we in continuing any type of ancient DNA project, assisted by fun little cartoony schematic diagrams (<a href="#fig-ancient-metagenomic-pipelines-eageroutputexample" class="quarto-xref">Figure&nbsp;<span>17.3</span></a>)!</p>
<div id="fig-ancient-metagenomic-pipelines-eageroutputexample" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancient-metagenomic-pipelines-eageroutputexample-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/damageprofiler_deaminationpatterns.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancient-metagenomic-pipelines-eageroutputexample-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.3: Example of cartoon schematic diagram of the output from <code>DamageProfiler</code> <span class="citation" data-cites="Neukamm2021-ul">(<a href="#ref-Neukamm2021-ul" role="doc-biblioref">Neukamm, Peltzer, and Nieselt 2021</a>)</span> in different contexts. The six panels show different types of ancient DNA damage line-plots from having no damage (flat red/blue lines), however with a speech bubble noting that if the library was UDG treated, that the flat lines might be valid, all the way to the ‘classic’ ancient DNA damage plot with both red and blue lines showing an exponential decay from the ends of reads to the middle, with a motivational speech bubble. Source: Zandra Fagernäs, CC-BY 4.0 via nf-core/eager documentation (<a href="https://nf-co.re/eager/output">https://nf-co.re/eager/output</a>).
</figcaption>
</figure>
</div>
</section>
<section id="clean-up" class="level3" data-number="17.3.5">
<h3 data-number="17.3.5" class="anchored" data-anchor-id="clean-up"><span class="header-section-number">17.3.5</span> Clean up</h3>
<p>Before continuing onto the next section of this chapter, we will need to deactivate from the conda environment.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If the nf-core/eager run is still not finished, we should enter the screen session with <code>screen -r eager</code>, press <kbd>ctrl</kbd> + <kbd>c</kbd> until we drop to the prompt, and type <code>exit</code>.</p>
<p>Then may also need to delete the contents of the eager directory if we are low on hard-drive space.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> /<span class="op">&lt;</span>path<span class="op">&gt;</span>/<span class="op">&lt;</span>to<span class="op">&gt;</span>/ancient-metagenomic-pipelines/eager</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> <span class="at">-r</span> <span class="pp">*</span> .nex<span class="pp">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="what-is-ameta" class="level2" data-number="17.4">
<h2 data-number="17.4" class="anchored" data-anchor-id="what-is-ameta"><span class="header-section-number">17.4</span> What is aMeta?</h2>
<div class="callout callout-style-default callout-note callout-titled" title="Self guided: chapter environment setup">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Self guided: chapter environment setup
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For this chapter’s exercises, if not already performed, we will need to create the special aMeta <a href="./before-you-start.html#creating-a-conda-environment">conda environment</a> and activate the environment.</p>
</div>
</div>
</div>
<p>While nf-core/eager is a solid pipeline for microbial genomics, and can also perform metagenomic screening via the integrated HOPS pipeline <span class="citation" data-cites="Hubler2019-qw">(<a href="#ref-Hubler2019-qw" role="doc-biblioref">Hübler et al. 2019</a>)</span> or <code>Kraken2</code> <span class="citation" data-cites="Wood2019-mf">(<a href="#ref-Wood2019-mf" role="doc-biblioref">Wood, Lu, and Langmead 2019</a>)</span>, in some cases we may wish to have a more accurate and resource efficient pipeline In this section, we will demonstrate an example of using aMeta, a <code>Snakemake</code> workflow proposed by <span class="citation" data-cites="Pochon2022-hj">Pochon et al. (<a href="#ref-Pochon2022-hj" role="doc-biblioref">2022</a>)</span> that aims to minimise resource usage by combining both low-resource requiring k-mer based taxonomic profiling as well as accurate read-alignment (<a href="#fig-ancientmetagenomicpipelines-ametadiagram" class="quarto-xref">Figure&nbsp;<span>17.4</span></a>).</p>
<div id="fig-ancientmetagenomicpipelines-ametadiagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-ametadiagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/ameta-workflow.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-ametadiagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.4: Schematic diagram of the aMeta pipeline. Input samples initially undergo generalised screening using the K-mer based <code>KrakenUniq</code>. For every hit that the reads match inside this database, then sees the genome of that hit then constructed into a MALT database where the reads undergo a mapping step to generate alignments, a lowest-common-ancestor (LCA) algorithm step to refine taxonomic assignments, and ancient DNA authentication statistics generation
</figcaption>
</figure>
</div>
<p>Rather than the very computationally heavy HOPS pipeline <span class="citation" data-cites="Hubler2019-qw">(<a href="#ref-Hubler2019-qw" role="doc-biblioref">Hübler et al. 2019</a>)</span>, that requires extremely large computational nodes with large RAM (&gt;1 TB) to load MALT databases into memory, aMeta does this via a two step approach. Firstly it uses <code>KrakenUniq</code> <span class="citation" data-cites="Breitwieser2018-xg">(a k-mer based and thus memory efficient method, <a href="#ref-Breitwieser2018-xg" role="doc-biblioref">Breitwieser, Baker, and Salzberg 2018</a>)</span> to do a screening of sequencing reads against a broad generalised microbial database. Once all the possible taxa have been detected, aMeta will then make a new database of just the genomes of the taxa that were reported from <code>KrakenUniq</code> (i.e. a project-specific database) but using <code>MALT. Then aMeta will use</code>MALT<code>on thus much reduced database to perform computationally much heavier alignment against the reference genomes and LCA taxonomic reassignment. The output from</code>MALT<code>is then sent to the</code>MaltExtract` program of the HOPS pipeline for ancient DNA authentication statistics.</p>
<section id="running-ameta" class="level3" data-number="17.4.1">
<h3 data-number="17.4.1" class="anchored" data-anchor-id="running-ameta"><span class="header-section-number">17.4.1</span> Running aMeta</h3>
<p>In this tutorial we will try running the small test data that comes with aMeta.</p>
<p>aMeta has been written in <code>Snakemake</code>, which means running the pipeline has to be installed in a slightly different manner to the <code>nextflow pull</code> command that can be used for nf-core/eager.</p>
<p>Make sure you have followed the instructions in the <a href="./before-you-start.html#ancient-metagenomic-pipelines">Before You Start Chapter</a> for cloning the aMeta GitHub repository to the <code>ancient-metagenomic-pipelines/</code> directory. Once we have done this, we can make sure we are in the aMeta directory, if not already.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> /<span class="op">&lt;</span>path<span class="op">&gt;</span>/<span class="op">&lt;</span>to<span class="op">&gt;</span>/ancient-metagenomic-pipelines/aMeta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And activate the dedicated aMeta conda environment.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate aMeta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As aMeta also includes tools that normally require very large computational resources that cannot fit on a standard laptop, we will instead try to re-use the internal very small ‘fake’ data the aMeta developers use to test the pipeline.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following steps are already performed up for Students in the summer schools as, particularly the <code>set up conda envs</code> will take a very long time!</p>
<p>If you are doing this chapter self-guided, it is critical to perform the following set up steps!</p>
<p>We don’t have to worry about trying to understand exactly what the following commands are doing, they will not be important for the rest of the chapter. However generally the commands try to pull all the relevant software (via conda), make a fake database and download other required files, and then reconstruct the basic directory and file structure required for running the pipeline.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Self-guided: aMeta set up and configuration">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Self-guided: aMeta set up and configuration
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb17"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Change into ~/.test to set up all the required test resources (Databases etc.)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> .test/</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Set up conda envs</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">## If we can an error about a 'non-default solver backend' the run `conda config --set solver classic` and re-start the command</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">## If we have installed the standalone mamba, change --conda-frontend to mamba</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="ex">snakemake</span> <span class="at">--use-conda</span> <span class="at">--show-failed-logs</span> <span class="at">-j</span> 2 <span class="at">--conda-cleanup-pkgs</span> cache <span class="at">--conda-create-envs-only</span> <span class="at">-s</span> ../workflow/Snakefile <span class="at">--conda-frontend</span> conda</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$(</span><span class="fu">dirname</span> <span class="va">$(</span><span class="fu">dirname</span> <span class="va">$CONDA_EXE))</span>/etc/profile.d/conda.sh</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">## If we had to change the solver back to classic, we can switch to libmamba with `conda config --set solver libmamba`</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Build dummy KrakenUniq database</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="va">env</span><span class="op">=</span><span class="va">$(</span><span class="fu">grep</span> krakenuniq .snakemake/conda/<span class="pp">*</span>yaml <span class="kw">|</span> <span class="fu">awk</span> <span class="st">'{print $1}'</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">"s/.yaml://g"</span><span class="va">)</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$env</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="ex">krakenuniq-build</span> <span class="at">--db</span> resources/KrakenUniq_DB <span class="at">--kmer-len</span> 21 <span class="at">--minimizer-len</span> 11 <span class="at">--jellyfish-bin</span> <span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span>/<span class="va">$env</span>/bin/jellyfish</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">## Get Krona taxonomy tax dump</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="va">env</span><span class="op">=</span><span class="va">$(</span><span class="fu">grep</span> krona .snakemake/conda/<span class="pp">*</span>yaml <span class="kw">|</span> <span class="fu">awk</span> <span class="st">'{print $1}'</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">"s/.yaml://g"</span> <span class="kw">|</span> <span class="fu">head</span> <span class="at">-1</span><span class="va">)</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$env</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="va">$env</span>/opt/krona</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="ex">./updateTaxonomy.sh</span> taxonomy</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="at">-</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co">## Adjust malt max memory usage</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="va">env</span><span class="op">=</span><span class="va">$(</span><span class="fu">grep</span> hops .snakemake/conda/<span class="pp">*</span>yaml <span class="kw">|</span> <span class="fu">awk</span> <span class="st">'{print $1}'</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">"s/.yaml://g"</span> <span class="kw">|</span> <span class="fu">head</span> <span class="at">-1</span><span class="va">)</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$env</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="va">version</span><span class="op">=</span><span class="va">$(</span><span class="ex">conda</span> list malt <span class="at">--json</span> <span class="kw">|</span> <span class="fu">grep</span> version <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">"s/</span><span class="dt">\"</span><span class="st">//g"</span> <span class="kw">|</span> <span class="fu">awk</span> <span class="st">'{print $2}'</span><span class="va">)</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="va">$env</span>/opt/malt-<span class="va">$version</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="fu">sed</span> <span class="at">-i</span> <span class="at">-e</span> <span class="st">"s/-Xmx64G/-Xmx3G/"</span> malt-build.vmoptions</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="fu">sed</span> <span class="at">-i</span> <span class="at">-e</span> <span class="st">"s/-Xmx64G/-Xmx3G/"</span> malt-run.vmoptions</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="at">-</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="fu">touch</span> .initdb</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="co">## Run a quick test and generate the report (you can open this to check it looks like everythin was generated)</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="ex">snakemake</span> <span class="at">--use-conda</span> <span class="at">--show-failed-logs</span> <span class="at">--conda-cleanup-pkgs</span> cache <span class="at">-s</span> ../workflow/Snakefile <span class="va">$@</span> <span class="at">--conda-frontend</span> conda <span class="at">-j</span> 4</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="ex">snakemake</span> <span class="at">-s</span> ../workflow/Snakefile <span class="at">--report</span> <span class="at">--report-stylesheet</span> ../workflow/report/custom.css <span class="at">--conda-frontend</span> conda</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="co">## Now we move back into the main repository where we can symlink all the database files back to try running our 'own' test</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ../</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> resources/</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="fu">ln</span> <span class="at">-s</span> ../.test/resources/<span class="pp">*</span> .</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ../config</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="fu">mv</span> config.yaml config.yaml.bkp</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="fu">mv</span> samples.tsv samplest.tsv.bkp</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ../</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="fu">ln</span> <span class="at">-s</span> .test/data/ .</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="fu">ln</span> <span class="at">-s</span> .test/.snakemake/ . <span class="co">## so we can re-use conda environments from the `.test` directory for the summer school run</span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a><span class="co">## Again get the taxonomy tax dump for Krona, but this time for a real run</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="co">## Make sure you're now in the root directory of the repository!</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="va">env</span><span class="op">=</span><span class="va">$(</span><span class="fu">grep</span> krona .test/.snakemake/conda/<span class="pp">*</span>yaml <span class="kw">|</span> <span class="fu">awk</span> <span class="st">'{print $1}'</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="at">-e</span> <span class="st">"s/.yaml://g"</span> <span class="kw">|</span> <span class="fu">head</span> <span class="at">-1</span><span class="va">)</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$env</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="va">$env</span>/opt/krona</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="ex">./updateTaxonomy.sh</span> taxonomy</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> <span class="at">-</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a><span class="co">## And back to the root of the repo for practising aMeta properly!</span></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ../</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now hopefully we can forget all this, and imagine we are running data though aMeta as you would normally from scratch.</p>
</div>
</div>
</div>
<p>OK now aMeta is all set up, we can now simulate running a ‘real’ pipeline job!</p>
</div>
</div>
</section>
<section id="ameta-configuration" class="level3" data-number="17.4.2">
<h3 data-number="17.4.2" class="anchored" data-anchor-id="ameta-configuration"><span class="header-section-number">17.4.2</span> aMeta configuration</h3>
<p>First, we will need to configure the workflow. First, we need to create a tab-delimited <code>samples.tsv</code> file inside <code>aMeta/config/</code> and provide the names of the input fastq-files. In a text editor (e.g.&nbsp;<code>nano</code>), write the following names paths in TSV format.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="ex">sample</span>  fastq</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="ex">bar</span> data/bar.fq.gz</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="ex">foo</span> data/foo.fq.gz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Make sure when copy pasting into our test editor, tabs are not replaced with spaces, otherwise the file might not be read!</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>aMeta (v1.0.0) currently only supports single-end or pre-merged- data only!</p>
</div>
</div>
<p>Then we need to write a config file. This tells aMeta where to find things such as database files and other settings.</p>
<p>A minimal example <code>config.yaml</code> files can look like this. This includes specifying the location the main samplesheet, which points to a TSV file that contains all the FASTQs if the samples we want to analyse, and paths to all the required database files and reference genomes you may need. These paths and settings go inside the <code>config.yaml</code> file that must be placed inside inside <code>aMeta/config/</code>.</p>
<p>Make a configuration file with your text editor of choice (e.g.&nbsp;<code>nano</code>).</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">samplesheet:</span> <span class="st">"config/samples.tsv"</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="ex">krakenuniq_db:</span> resources/KrakenUniq_DB</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="ex">bowtie2_db:</span> resources/ref.fa</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="ex">bowtie2_seqid2taxid_db:</span> resources/seqid2taxid.pathogen.map</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="ex">pathogenomesFound:</span> resources/pathogenomesFound.tab</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="ex">malt_nt_fasta:</span> resources/ref.fa</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="ex">malt_seqid2taxid_db:</span> resources/KrakenUniq_DB/seqid2taxid.map</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="ex">malt_accession2taxid:</span> resources/accession2taxid.map</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="ex">ncbi_db:</span> resources/ncbi</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="ex">n_unique_kmers:</span> 1000</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="ex">n_tax_reads:</span> 200</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once this config file is generated, we can start the run.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As this is only a dummy run (due to the large-ish computational resources required for <code>MALT</code>), we re-use some of the resource files here. While this will produce nonsense output, it is used here to demonstrate how we would execute the pipeline.</p>
</div>
</div>
</section>
<section id="prepare-and-run-ameta" class="level3" data-number="17.4.3">
<h3 data-number="17.4.3" class="anchored" data-anchor-id="prepare-and-run-ameta"><span class="header-section-number">17.4.3</span> Prepare and run aMeta</h3>
<p>Make sure we’re still in the <code>aMeta</code> conda environment, and that we are still in the main aMeta directory with the following.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate aMeta</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> /<span class="op">&lt;</span>path/<span class="op">&lt;</span>to<span class="op">&gt;</span>/ancient-metagenomic-pipelines/aMeta/</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, we are ready to run aMeta, where it will automatically pick up our config and samplesheet file we placed in <code>config/</code>!</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">## change conda-frontend to mamba if we set this up earlier!</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="ex">snakemake</span> <span class="at">--snakefile</span> workflow/Snakefile <span class="at">--use-conda</span> <span class="at">-j</span> 10 <span class="at">--conda-frontend</span> conda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We can modify <code>-j</code> to represent the number of available CPUs we have on our machine.</p>
<p>If we are using <code>conda</code> is the frontend this could be quite slow!</p>
</div>
</div>
<p>Firstly we’ll have displayed on the console a bunch of messages about JSON schemas, building DAG of jobs and downloading installing of conda environments. We will know the pipeline has started when we get green messages saying things like <code>Checkpoint</code> and <code>Finished job XX</code>.</p>
<p>We’ll know the job is completed once we get the following messages</p>
<pre class="verbatim"><code>Finished job 0.
31 of 31 steps (100%) done
Complete log: .snakemake/log/2023-10-05T155051.524987.snakemake.log</code></pre>
</section>
<section id="ameta-output" class="level3" data-number="17.4.4">
<h3 data-number="17.4.4" class="anchored" data-anchor-id="ameta-output"><span class="header-section-number">17.4.4</span> aMeta output</h3>
<p>All output files of the workflow are located in <code>aMeta/results</code> directory. To get a quick overview of ancient microbes present in our samples we should check a heatmap in <code>results/overview_heatmap_scores.pdf</code>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>If running during the summer school, you can use the following command to open the PDF file from the command line.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">evince</span> results/overview_heatmap_scores.pdf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="fig-ancientmetagenomicpipelines-ametaoutput" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-ametaoutput-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/overview_heatmap_scores.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-ametaoutput-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.5: Example microbiome profiling summary heatmap from aMeta. The columns represent different samples, and the rows of different species. The cells of the heatmap are coloured from blue, to yellow, to red, representing aMeta authentication scores from 0 to 10, with the higher the number the more confident of the hit being both the correct taxonomic assignment and that it is ancient. Numbers in the coloured cells also provide the direct score number.
</figcaption>
</figure>
</div>
<p>The heatmap demonstrates microbial species (in rows) authenticated for each sample (in columns) (<a href="#fig-ancientmetagenomicpipelines-ametaoutput" class="quarto-xref">Figure&nbsp;<span>17.5</span></a>).</p>
<p>The colors and the numbers in the heatmap represent authentications scores, i.e. numeric quantification of eight quality metrics that provide information about microbial presence and ancient status.</p>
<p>The authentication scores can vary from 0 to 10, the higher is the score the more likely that a microbe is present in a sample and is ancient.</p>
<p>Typically, scores from 8 to 10 (red color in the heatmap) provide good confidence of ancient microbial presence in a sample. Scores from 5 to 7 (yellow and orange colors in the heatmap) can imply that either: (a) a microbe is present but not ancient, i.e. modern contaminant, or (b) a microbe is ancient (the reads are damaged) but was perhaps aligned to a wrong reference, i.e. it is not the microbe we think about.</p>
<p>The former is a more common case scenario.</p>
<p>The latter often happens when an ancient microbe is correctly detected on a genus level but we are not confident about the exact species, and might be aligning the damaged reads to a non-optimal reference which leads to a lot of mismatches or poor evennes of coverage. Scores from 0 to 4 (blue color in the heatmap) typically mean that we have very little statistical evidence (very few reads) to claim presence of a microbe in a sample.</p>
<p>To visually examine the seven quality metrics</p>
<ul>
<li>Deamination profile</li>
<li>Evenness of coverage</li>
<li>Edit distance (amount of mismatches) for all reads</li>
<li>Edit distance (amount of mismatches) for damaged reads</li>
<li>Read length distribution</li>
<li>PMD scores distribution</li>
<li>Number of assigned reads (depth of coverage)</li>
<li>average nucleotide identity (ANI)</li>
</ul>
<p>Corresponding to the numbers and colors of the heatmap, one can find them in <code>results/AUTHENTICATION/sampleID/taxID/authentic_&lt;Sample&gt;_&lt;sampleID&gt;.trimmed.rma6_&lt;TaxID&gt;_&lt;taxID&gt;.pdf</code> for each sample sampleID and each authenticated microbe taxID. An example of such quality metrics is shown below in <a href="#fig-ancientmetagenomicpipelines-persampleplot" class="quarto-xref">Figure&nbsp;<span>17.6</span></a>.</p>
<div id="fig-ancientmetagenomicpipelines-persampleplot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-persampleplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/aMeta_output.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-persampleplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.6: Example of sample/hit specific PDF output from aMeta, 9 panels represent different figures that are useful for evaluating the authenticitiy of an ancient metagenomic hit. From Left to Right, Top from bottom, the panels consists of: 1. Edit distance (all reads) bar plot 2. Edit distance (ancient reads) bar plot 3. Breadth of coverage line plot 4. Deamination line plot 5. Read length distribution bar plot 6. PMD score histogram 7. Percent identity bar plot, 8. A table of similarity to hits from from closest hit to least closest 9. A general statistics table including the name of the taxonomic node, number of reads, duplicates, and mean read length etc.
</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>In our test data, what score does the sample ‘foo’ for the hit against <em>Yersinia pestis</em>? Is this a good score?</p>
<p>Inspect the results <code>AUTHENTICATION/xxx/authentic_Sample_foo_*.pdf</code> file What could have contributed to this particular score?</p>
<p>Hint: Check Supplementary File 2, section S5 of <span class="citation" data-cites="Pochon2022-hj">(<a href="#ref-Pochon2022-hj" role="doc-biblioref">Pochon et al. 2022</a>)</span> for some hints.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-27-contents" aria-controls="callout-27" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-27" class="callout-27-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The sample foo gets a score of <code>4</code>. This is a low score, and indicates that aMeta is not very confident that this is a true hit. The metrics that contribute to this score are:</p>
<ul>
<li>Edit distance all reads (+1)</li>
<li>Deamination plot (+2)</li>
<li>Reads mapped with identity (+1),</li>
</ul>
</div>
</div>
</div>
</section>
<section id="clean-up-1" class="level3" data-number="17.4.5">
<h3 data-number="17.4.5" class="anchored" data-anchor-id="clean-up-1"><span class="header-section-number">17.4.5</span> Clean up</h3>
<p>Before continuing onto the next section of this chapter, we will need to remove the output files, and deactivate from the conda environment.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> <span class="at">-r</span> results/ log/</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">## You can also optionall remove the conda environments if we are running out of space</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># rm -r .snakemake/ .test/.snakemake</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="what-is-nf-coremag" class="level2" data-number="17.5">
<h2 data-number="17.5" class="anchored" data-anchor-id="what-is-nf-coremag"><span class="header-section-number">17.5</span> What is nf-core/mag?</h2>
<p>nf-core/mag <span class="citation" data-cites="Krakau2022-we">(<a href="#ref-Krakau2022-we" role="doc-biblioref">Krakau et al. 2022</a>)</span> is another <code>Nextflow</code> best-practise pipeline for the <em>de novo</em> assembly, binning, and annotation of metagenomes (<a href="#fig-ancientmetagenomicpipelines-magworkflow" class="quarto-xref">Figure&nbsp;<span>17.7</span></a>). While it was originally designed for modern metagenomes (with a focus on optional support co-assembly with Nanopore long reads), it has since been updated to include specific functionality and parameters for ancient metagenomes too.</p>
<div id="fig-ancientmetagenomicpipelines-magworkflow" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ancientmetagenomicpipelines-magworkflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/images/chapters/ancient-metagenomic-pipelines/mag_workflow.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ancientmetagenomicpipelines-magworkflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17.7: Overview diagram of the main steps and tools of the nf-core/mag pipeline. Taking reads in FASTQ format or a samplesheet as input, reads can go through adapter and/or quality trimming for specific tools for both short and long reads. These reads can optionally go into taxonomic classification and visualisation, at the same time as the prepared reads go into sample-or group wise assemply, evaluation, as well as the ancient DNA valdiation subworkflow. Resulting contigs can be functionally annotated at the same time as optionally going through binning and binning refinement and evaluation (with statistics generation). Bins and refined bins can be taxonomically classified and annotated, with all final reports going into <code>MultiQC</code>.
</figcaption>
</figure>
</div>
<p>nf-core/mag covers the same major steps as we will have run if we followed the chapter on <a href="./denovo-assembly.html">De Novo assembly</a>.</p>
<p>Firstly, as with nf-core/eager, nf-core/mag do some initial sequencing QC and cleanup with <code>fastp</code> <span class="citation" data-cites="Chen2018-vg">(<a href="#ref-Chen2018-vg" role="doc-biblioref">Chen et al. 2018</a>)</span> or <code>AdapterRemoval</code> <span class="citation" data-cites="Schubert2016-qv">(<a href="#ref-Schubert2016-qv" role="doc-biblioref">Schubert, Lindgreen, and Orlando 2016</a>)</span>, running <code>FastQC</code> <span class="citation" data-cites="Andrews2010-pd">(<a href="#ref-Andrews2010-pd" role="doc-biblioref">Andrews 2010</a>)</span> before and after this step to make sure that adapters and overly short reads have been removed. It can then optionally do basic taxonomic classification of raw reads with <code>Kraken2</code> <span class="citation" data-cites="Wood2019-mf">(<a href="#ref-Wood2019-mf" role="doc-biblioref">Wood, Lu, and Langmead 2019</a>)</span> or <code>Centrifuge</code> <span class="citation" data-cites="Kim2016-qc">(<a href="#ref-Kim2016-qc" role="doc-biblioref">Kim et al. 2016</a>)</span>. The processed reads then ungo assembly with <code>MEGAHIT</code> <span class="citation" data-cites="Li2015-lj">(<a href="#ref-Li2015-lj" role="doc-biblioref">Li et al. 2015</a>)</span>, <code>metaSPAdes</code> <span class="citation" data-cites="Nurk2017-xh">(<a href="#ref-Nurk2017-xh" role="doc-biblioref">Nurk et al. 2017</a>)</span>, or <code>SPAdeshybrid</code> <span class="citation" data-cites="Antipov2016-xw">(<a href="#ref-Antipov2016-xw" role="doc-biblioref">Antipov et al. 2016</a>)</span> (the latter being for combining short and long reads), with contig annotation with <code>Prodigal</code> <span class="citation" data-cites="Hyatt2010-yv">(<a href="#ref-Hyatt2010-yv" role="doc-biblioref">Hyatt et al. 2010</a>)</span> to get gene prediction and assembly statistics with <code>QUAST</code>. A unique feature of nf-core/mag over other <em>de novo</em> assembly pipelines is an aDNA validation and correction step: contigs under go ‘reference free’ damage profiling using <code>pyDamage</code> <span class="citation" data-cites="Borry2021-lt">(<a href="#ref-Borry2021-lt" role="doc-biblioref">Borry et al. 2021</a>)</span>, and then remaining damage bases that are mistakenly incorporated by assemblies are corrected using <code>freebayes</code> <span class="citation" data-cites="Garrison2012-pv">(<a href="#ref-Garrison2012-pv" role="doc-biblioref">Garrison and Marth 2012</a>)</span> and <code>BCFTools</code>. Contigs then optionally grouped into genomic ‘bins’ with a range of metagenomic binners (<code>MetaBAT2</code> <span class="citation" data-cites="Kang2019-ld">(<a href="#ref-Kang2019-ld" role="doc-biblioref">Kang et al. 2019</a>)</span>, <code>MaxBin2</code> <span class="citation" data-cites="Wu2015-bz">(<a href="#ref-Wu2015-bz" role="doc-biblioref">Wu, Simmons, and Singer 2015</a>)</span>, and <code>CONCOCT</code> <span class="citation" data-cites="Alneberg2014-mc">(<a href="#ref-Alneberg2014-mc" role="doc-biblioref">Alneberg et al. 2014</a>)</span>), as well as also optional binning refinement with <code>DAS Tool</code> <span class="citation" data-cites="Sieber2018-jt">(<a href="#ref-Sieber2018-jt" role="doc-biblioref">Sieber et al. 2018</a>)</span>. Bins are then re-annotated with <code>Prokka</code> <span class="citation" data-cites="Seemann2014-ee">(<a href="#ref-Seemann2014-ee" role="doc-biblioref">Seemann 2014</a>)</span>, taxonomically classified with either <code>CAT</code> <span class="citation" data-cites="von-Meijenfeldt2019-qe">(<a href="#ref-von-Meijenfeldt2019-qe" role="doc-biblioref">Meijenfeldt et al. 2019</a>)</span> or <code>GTDB-Tk</code> <span class="citation" data-cites="Chaumeil2022-xx">(<a href="#ref-Chaumeil2022-xx" role="doc-biblioref">Chaumeil et al. 2022</a>)</span> Evaluation of the resulting bins is carried out with <code>BUSCO</code> <span class="citation" data-cites="Simao2015-bs">(<a href="#ref-Simao2015-bs" role="doc-biblioref">Simão et al. 2015</a>)</span>, <code>CheckM</code> <span class="citation" data-cites="Parks2015-zg">(<a href="#ref-Parks2015-zg" role="doc-biblioref">Parks et al. 2015</a>)</span>, <code>GUNC</code> <span class="citation" data-cites="Orakov2021-yq">(<a href="#ref-Orakov2021-yq" role="doc-biblioref">Orakov et al. 2021</a>)</span> and/or <code>QUAST</code> <span class="citation" data-cites="Gurevich2013-iq">(<a href="#ref-Gurevich2013-iq" role="doc-biblioref">Gurevich et al. 2013</a>)</span> to assess the bin completeness. And, as with all nf-core pipelines, all the results are wrapped up into a <code>MultiQC</code> report. Detailed documentation can be see on the nf-core/mag parameters (<a href="https://nf-co.re/mag/2.3.2/parameters">https://nf-co.re/mag/2.3.2/parameters</a>) and output (<a href="https://nf-co.re/mag/2.3.2/docs/output">https://nf-co.re/mag/2.3.2/docs/output</a> pages.</p>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why do we need ancient DNA specific steps in a <em>de novo</em> assembly pipeline?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-29-contents" aria-controls="callout-29" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-29" class="callout-29-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Firstly we need a method of validating that contigs are from an ancient genome (in nf-core/mag, damage patterns are generated by <code>pyDamage</code>).</p>
<p>Secondly, to correct for falsely included damage bases in contigs in some contexts. As previously stated a previous chapter by Alex Hübner:</p>
<blockquote class="blockquote">
<p>In our group we realised that the gene sequences that were annotated on the contigs of MEGAHIT tended to have a higher number of nonsense mutations compared to the known variants of the genes. After manual inspection, we observed that many of these mutations appeared because MEGAHIT chose the damage-derived T allele over the C allele or the damage-derived A allele over a G allele <span class="citation" data-cites="Klapper2023-nv">(see <a href="#ref-Klapper2023-nv" role="doc-biblioref">Klapper et al. 2023, fig. S1</a>)</span>.</p>
</blockquote>
<blockquote class="blockquote">
<p>To overcome this issue, my colleagues Maxime Borry, James Fellows Yates and I developed a strategy to replace these damage-derived alleles in the contig sequences. This approach consists of aligning the short-read data against the contigs, performing genotyping along them, and finally replacing all alleles for which we have strong support for an allele that is different from the one selected by MEGAHIT.</p>
</blockquote>
<p><em>See the <a href="./denovo-assembly.html"><em>De novo</em> assembly chapter</a> for full context</em>.</p>
</div>
</div>
</div>
<section id="running-nf-coremag" class="level3" data-number="17.5.1">
<h3 data-number="17.5.1" class="anchored" data-anchor-id="running-nf-coremag"><span class="header-section-number">17.5.1</span> Running nf-core/mag</h3>
<p>First re-activate the chapter’s conda environment.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate ancient-metagenomic-pipelines</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this tutorial, we will use the same data and aim to replicate the steps taken in the <a href="./denovo-assembly.html">De Novo assembly</a> chapter. It is important to note that generally, <em>de novo</em> assembly, is very computational intensive. In many cases it will not be able to run a <em>de novo</em> assembly on a standard laptop, therefore some of the parameters used here have been tweaked to get the pipeline runable on powerful laptop level machines.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Self guided: reference download and preparation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Self guided: reference download and preparation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This tutorial will re-use the data from the <em>de novo</em> assembly chapter. If we have not-run that practical, or deleted the data, pleas follow the instructions at the top of the <a href="./denovo-assembly.html">de novo assembly</a> page to download the <code>denovo-assembly.tar.gz</code> file and unpack it into the <code>denovo-assembly directory</code>.</p>
<p>Make sure once we’ve finished, change back into this chapter’s directory with the following.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> /<span class="op">&lt;</span>path<span class="op">&gt;</span>/<span class="op">&lt;</span>to<span class="op">&gt;</span>/ancient-metagenomic-pipelines</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>The manual steps of the previous chapter included:</p>
<ol type="1">
<li>Read clean up with <code>fastp</code>,</li>
<li>Assembly with <code>MEGAHIT</code>,</li>
<li>Ancient DNA assessment and correction with <code>freebayes</code> and <code>pyDamage</code></li>
<li>Binning using <code>MetaBAT2</code> and <code>MaxBin2</code> (originally using the <code>MetaWRAP</code> pipeline <span class="citation" data-cites="Uritskiy2018-ut">(<a href="#ref-Uritskiy2018-ut" role="doc-biblioref">Uritskiy, DiRuggiero, and Taylor 2018</a>)</span>),</li>
<li>Bin assessment with <code>CheckM</code></li>
<li>Contig taxonomic classification with <code>MMSeqs2</code> <span class="citation" data-cites="Steinegger2017-qt">(<a href="#ref-Steinegger2017-qt" role="doc-biblioref">Steinegger and Söding 2017</a>)</span> via the <code>GTDB</code> database</li>
<li>Genome annotation with <code>Prokka</code></li>
</ol>
<p>So, what command would we use to recreate these?</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">## 🛑 Don't run this yet! 🛑</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="ex">nextflow</span> run nf-core/mag <span class="at">-r</span> 2.3.2 <span class="dt">\</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>-profile test,docker <span class="dt">\</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>--input <span class="st">'../../denovo-assembly/seqdata_files/*{R1,R2}.fastq.gz'</span> <span class="at">--outdir</span> ./results <span class="dt">\</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>--ancient_dna  <span class="at">--binning_map_mode</span> own <span class="dt">\</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>--binqc_tool checkm <span class="at">--checkm_db</span> data/checkm_data_2015_01_16/ <span class="dt">\</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>--centrifuge_db false <span class="at">--kraken2_db</span> false <span class="at">--skip_krona</span> <span class="at">--skip_spades</span> <span class="at">--skip_spadeshybrid</span> <span class="at">--skip_maxbin2</span> <span class="at">--skip_concoct</span> <span class="at">--skip_prodigal</span> <span class="at">--gtdb</span> false  <span class="at">--busco_reference</span> false </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In fact, nf-core/mag will do most of the steps for us! In this case, we mostly just need to <em>deactivate</em> most of the additional steps (the last line). Otherwise, as with eager we have done the following:</p>
<ol type="1">
<li>Tell <code>Nextflow</code> to run the nf-core/mag pipeline with version 2.3.2</li>
<li>Specify which computing and software environment to use with <code>-profile</code>
<ul>
<li>In this case we are running locally so we don’t specify a computing environment (such as a configuration for an institutional HPC)</li>
<li>We use <code>docker</code> as our container engine, which downloads all the software and specific versions needed for nf-core/mag in immutable ‘containers’, to ensure nothing get broken and is as nf-core/mag expects</li>
</ul></li>
<li>Provide the various paths to the input files - the raw FASTQ files and the output directory</li>
<li>Specify we want to run the aDNA mode with mapping of reads back to the original contigs rather than for co-assembly</li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled" title="Binning mapping mode with ancient DNA">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-31-contents" aria-controls="callout-31" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Binning mapping mode with ancient DNA
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-31" class="callout-31-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The aDNA mode of nf-core/mag <em>only</em> supports mapping reads back to the original contigs. The other mapping modes are when doing co-assembly, where we assume there are similar organisms across all our metagenomes, and wish to map reads from all samples in a group to a single sample’s contig (for example). Doing this on aDNA reads would risk making false positive damage patterns, as the damaged reads may derive from reads from a different sample with damage, that are otherwise not present in the sample used for generating the given contig.</p>
</div>
</div>
</div>
<p>5 . Specify we want to generate completeness statistics with <code>CheckM</code> (rather than <code>BUSCO</code>), with the associated pre-downloaded database</p>
<div class="callout callout-style-default callout-note callout-titled" title="nf-core pipelines and reference files">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-32-contents" aria-controls="callout-32" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
nf-core pipelines and reference files
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-32" class="callout-32-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Most nf-core pipelines will actually download reference databases, build reference indices for alignment, and in some cases reference genomes for we if we do not specify them as pipeline input. These download and reference building steps are often very time consuming, so it’s recommended that once we’ve let the database download it once, we should move the files somewhere safe and we can re-use in subsequent pipeline runs.</p>
</div>
</div>
</div>
<p>6 . Skip a few steps that are either ‘nice to have’ (e.g.&nbsp;read taxonomic classification), or require large computational resources (e.g.<code>metaSPAdes</code>, <code>CONCOCT</code> or <code>BUSCO</code>)</p>
<div class="callout callout-style-default callout-note callout-titled" title="Information on skipped tests">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-33-contents" aria-controls="callout-33" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Information on skipped tests
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-33" class="callout-33-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The steps we are skipping are: host/arefact removal (<code>Bowtie2</code> removal of phiX), taxonomic classification of reads (<code>centrifuge</code>, <code>kraken2</code>, <code>krona</code>), the additional assemblers (<code>metaSPAdes</code> and <code>SPAdeshybrid</code>, as these require very large computational resources), additional binners (<code>MaxBin2</code> and <code>CONCOCT</code>, while they are used in the <em>de novo</em> assembly chapter, they take a long time to run), ship raw contig annotation (with <code>Prodigal</code>, as we do this at the bin level), and contig taxonomic classification (with <code>GTDB</code> and <code>BUSCO</code> as they require very large databases).</p>
</div>
</div>
</div>
<p>With this we are almost ready for running the pipeline!</p>
</section>
<section id="configuring-nextflow-pipelines" class="level3" data-number="17.5.2">
<h3 data-number="17.5.2" class="anchored" data-anchor-id="configuring-nextflow-pipelines"><span class="header-section-number">17.5.2</span> Configuring Nextflow pipelines</h3>
<p>Before we execute the command however, we need to again consider about the resource requirements. As described above, particularly <em>de novo</em> assembly (but also many other bioinformatic analyses) require a lot of computational resources, depending on the type of data and analyses we wish to run.</p>
<p>For most pipelines we must tweak the resource requirements to ensure a) they will fit on our cluster, and b) will run optimally so we don’t under- or over- use our computational resources, where latter will either make ourselves (takes too long), or our cluser/server system administrators (blocks other users) unhappy!</p>
<p>While nf-core pipelines all have ‘reasonable default’ settings for memory, CPU, and time limits, they will not work in all contexts. Here we will give a brief example of how to tweak the parameters of the pipeline steps so that they can run on our compute node or laptop.</p>
<p>For <code>Nextflow</code>, we must make a special ‘config’ that defines the names of each step of the pipeline we wish to tweak and the corresponding resources.</p>
<p>For this our nf-core/mag run we will need to open our text editor an empty file called <code>custom.config</code>, and copy and paste the contents of the next code block.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode groovy code-with-copy"><code class="sourceCode groovy"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>process <span class="op">{</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> FASTP <span class="op">{</span> </span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> BOWTIE2_PHIX_REMOVAL_ALIGN <span class="op">{</span> </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> BOWTIE2_ASSEMBLY_ALIGN <span class="op">{</span>    </span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> PYDAMAGE_ANALYZE <span class="op">{</span>      </span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> PROKKA <span class="op">{</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> MEGAHIT <span class="op">{</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    cpus <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>  withName<span class="op">:</span> CHECKM_LINEAGEWF<span class="op">{</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    memory <span class="op">=</span> <span class="fl">24.</span>GB</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    cpus   <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>    ext<span class="op">.</span>args <span class="op">=</span> <span class="st">"--reduced_tree"</span></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here we set the number of CPUs for most tools to a maximum of <code>8</code>, and then we limit the amount of memory for CheckM to 24 GB (down from the default (<a href="https://github.com/nf-core/mag/blob/66cf53aff834d2a254b78b94fc54cd656b8b7b57/conf/base.config#L37-L41">https://github.com/nf-core/mag/blob/66cf53aff834d2a254b78b94fc54cd656b8b7b57/conf/base.config#L37-L41</a>) of 36 GB - which exceeds most laptop memory). We also give a specifc <code>CheckM</code> flag command to use a smaller database.</p>
<p>We can save this <code>custom.config</code> file, and supply this to the <code>Nextflow</code> command with the <code>Nextflow</code> parameter (<code>-c</code>). The good thing about the config file, is we can re-use across runs on the same machine! So set once, and never think about it again.</p>
<p>And with that, we can run our nf-core/mag pipeline!</p>
<p>As recommended in the nf-core/eager section above, start a screen session.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">screen</span> <span class="at">-R</span> mag</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then execute the command.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">nextflow</span> run nf-core/mag <span class="at">-r</span> 2.3.2 <span class="dt">\</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>-profile test,docker <span class="dt">\</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>--input <span class="st">'../../denovo-assembly/seqdata_files/*{R1,R2}.fastq.gz'</span> <span class="at">--outdir</span> ./results <span class="dt">\</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>--ancient_dna  <span class="at">--binning_map_mode</span> own <span class="dt">\</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>--binqc_tool checkm <span class="at">--checkm_db</span> data/checkm_data_2015_01_16/ <span class="dt">\</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>--centrifuge_db false <span class="at">--kraken2_db</span> false <span class="at">--skip_krona</span> <span class="at">--skip_spades</span> <span class="at">--skip_spadeshybrid</span> <span class="at">--skip_maxbin2</span> <span class="at">--skip_concoct</span> <span class="at">--skip_prodigal</span> <span class="at">--gtdb</span> false  <span class="at">--busco_reference</span> false <span class="dt">\</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>-c custom.config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Again as with nf-core/eager when the run starts, we see a long list of <code>process</code> lines with progress bars slowly appearing over time. If in a screen session, we can press <kbd>ctrl</kbd> + <kbd>a</kbd> and then <kbd>[</kbd> to access a ‘navigation’ (called ‘copy’) mode, then use our arrow keys on our keyboard to scroll up and down. To quit this mode just press <code>q</code>.</p>
<p>The pipeline run above should take around 20 minutes or so to complete.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Configuration files don’t need be personal nor custom!</p>
<p>We can also generate a HPC / server specific profile which can be used on all nf-core pipelines (and even our own!).</p>
<p>See nf-co.re/configs (<a href="https://nf-co.re/configs">https://nf-co.re/configs</a>) for all existing institutional configs</p>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Question">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why should you make sure to configure pipeline that use a workflow manager in the backend?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Answer">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-36-contents" aria-controls="callout-36" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-36" class="callout-36-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The primary reason for optimising the configuration of workflow managers is efficiency.</p>
<p>By correctly configuring your can ensure:</p>
<ol type="1">
<li>A maximal number of jobs can run in parallel</li>
<li>Runs are not killed (and repeatedly retried) if they request too many resources</li>
<li>Can reuse files across runs, such as databases and software containers</li>
</ol>
<p>amongst others.</p>
</div>
</div>
</div>
</section>
<section id="nf-coremag-output-results-files" class="level3" data-number="17.5.3">
<h3 data-number="17.5.3" class="anchored" data-anchor-id="nf-coremag-output-results-files"><span class="header-section-number">17.5.3</span> nf-core/mag output: results files</h3>
<p>As with nf-core/eager, we will have a results directory containing many folders representing different stages of the pipeline, and a <code>MultiQC</code> report.</p>
<p>Relevant directories for evaluting our assemblies are as follows:</p>
<ul>
<li><code>QC_shortreads/</code>
<ul>
<li>Contains various folders from the sequencing QC and raw read processing (e.g., <code>FastQC</code>, <code>fastp</code>/<code>AdapterRemoval</code>, host-removal results etc.)</li>
</ul></li>
<li><code>Taxonomy/</code>
<ul>
<li>If we have not already performed taxonomic classification of our reads, the output of the <code>Kraken2</code> or <code>Centrifuge</code> integrated steps of nf-core/mag will be deposited here, including an optional Krona piechart</li>
<li>If activated, the contig-level taxonomic assignments will be deposited here (e.g., from <code>CAT</code> or <code>GTDB</code>)</li>
</ul></li>
<li><code>Assembly/</code>
<ul>
<li>This directory will contain one directory per chosen assembler which will contain per-sample output files for each assembly.</li>
<li>Within each of the assembler sub directories, a QC folder will contain the <code>QUAST</code> output</li>
</ul></li>
<li><code>Ancient_DNA</code>
<ul>
<li>This folder will contain the output of <code>pyDamage</code> contig authentication to allow we to select or filter for just putatively ancient contigs</li>
</ul></li>
<li><code>variant_calling</code>
<ul>
<li>This directory will contain the ‘damage-corrected’ contigs that will be used in downstream steps of the pipeline, if the <code>aDNA</code> mode is turned on</li>
</ul></li>
<li><code>GenomeBinning/</code>
<ul>
<li>This directory will contain all the output from each of any of the selected contig binning tools. As well as the binned FASTAs, we also have read-depth statistics from when input reads are re-mapped back to the contigs</li>
<li>The directory will also contain the output from the <code>DASTool</code> binning refinement if turned on</li>
<li>In the <code>QC</code> sub-directory of this folder, we will find the QUAST results on the genome <em>bins</em> (rather than raw contigs as above), as well as <code>BUSCO</code>/<code>CheckM</code>/<code>GUNC</code> MAG completeness estimates</li>
</ul></li>
<li><code>Prodigal</code> / <code>Prokka</code>
<ul>
<li>These directories will contain the genome annotation output of the raw contigs (<code>Prodigal</code>) or from bins (<code>Prokka</code>)</li>
</ul></li>
</ul>
</section>
<section id="nf-coremag-output-run-report" class="level3" data-number="17.5.4">
<h3 data-number="17.5.4" class="anchored" data-anchor-id="nf-coremag-output-run-report"><span class="header-section-number">17.5.4</span> nf-core/mag output: run report</h3>
<p>For MultiQC, many of the questions asked in the preprocessing section of the <a href="#nf-coreeager-output-run-report">nf-core/eager</a> results interpretation will also apply here.</p>
<p>Other than the QUAST results in the <code>Assembly/*/QC/</code> or <code>GenomeBinning/*/QC/</code> directories, the main table used for evaluating the output files is the <code>bin_summary.tsv</code> table in the <code>GenomeBinning/</code> directory.</p>
<p>In this file we woud typically want to assess the following columns:</p>
<ul>
<li><p><code>% Complete *</code> columns - with the higher the number of expected domain-specific genes, normally representing a better quality of the resulting bin.</p></li>
<li><p><code># contigs (&gt;=* bp)</code> columns - which represnts the number of contigs at different lengths, the fewer the shorter reads and the greater the longer reads we have again suggests a better assembly.</p></li>
<li><p>This can also be evaluated by the N50 or L75 columns (as described in the <a href="./denovo-assembly.html"><em>De novo</em> assembly chapter</a>).</p></li>
<li><p><code>fastani</code> and <code>closest_placement_taxonomy</code> - these can tell we if our particular bin has a genome very similar to existing species in taxonomic databases</p></li>
<li><p><code>warnings</code> - for specific comments on each assignment</p></li>
</ul>
</section>
</section>
<section id="optional-clean-up" class="level2" data-number="17.6">
<h2 data-number="17.6" class="anchored" data-anchor-id="optional-clean-up"><span class="header-section-number">17.6</span> (Optional) clean-up</h2>
<p>Let’s clean up our working directory by removing all the data and output from this chapter.</p>
<p>The command below will remove the <code>/&lt;PATH&gt;/&lt;TO&gt;/ancient-metagenomic-pipelines</code> directory <em>as well as all of its contents</em>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pro Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always be VERY careful when using <code>rm -r</code>. Check 3x that the path we are specifying is exactly what we want to delete and nothing more before pressing ENTER!</p>
</div>
</div>
<div class="sourceCode" id="cb31"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span> <span class="at">-rf</span> /<span class="op">&lt;</span>PATH<span class="op">&gt;</span>/<span class="op">&lt;</span>TO<span class="op">&gt;</span>/ancient-metagenomic-pipelines<span class="pp">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once deleted we can move elsewhere (e.g., <code>cd ~</code>).</p>
<p>We can also get out of the <code>conda</code> environment with the following.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> deactivate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To delete the conda environment we can use <code>conda remove</code>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> remove <span class="at">--name</span> ancient-metagenomic-data <span class="at">--all</span> <span class="at">-y</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="questions-to-think-about" class="level2" data-number="17.7">
<h2 data-number="17.7" class="anchored" data-anchor-id="questions-to-think-about"><span class="header-section-number">17.7</span> Questions to think about</h2>
<ol type="1">
<li>Why is it important to use a pipeline for genomic analysis of ancient data?</li>
<li>How can the design of pipelines such as nf-core/eager pipeline help researchers comply with the FAIR principles for management of scientific data?</li>
<li>What metrics do we use to evaluate the success/failure of ancient DNA sequencing experiments? How can these measures be evaluated when using nf-core/eager for data preprocessing and analysis?</li>
</ol>
</section>
<section id="references" class="level2" data-number="17.8">
<h2 data-number="17.8" class="anchored" data-anchor-id="references"><span class="header-section-number">17.8</span> References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Alneberg2014-mc" class="csl-entry" role="listitem">
Alneberg, Johannes, Brynjar Smári Bjarnason, Ino de Bruijn, Melanie Schirmer, Joshua Quick, Umer Z Ijaz, Leo Lahti, Nicholas J Loman, Anders F Andersson, and Christopher Quince. 2014. <span>“Binning Metagenomic Contigs by Coverage and Composition.”</span> <em>Nature Methods</em> 11 (11): 1144–46. <a href="https://doi.org/10.1038/nmeth.3103">https://doi.org/10.1038/nmeth.3103</a>.
</div>
<div id="ref-Andrades_Valtuena2022-tq" class="csl-entry" role="listitem">
Andrades Valtueña, Aida, Gunnar U Neumann, Maria A Spyrou, Lyazzat Musralina, Franziska Aron, Arman Beisenov, Andrey B Belinskiy, et al. 2022. <span>“Stone Age Yersinia Pestis Genomes Shed Light on the Early Evolution, Diversity, and Ecology of Plague.”</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 119 (17): e2116722119. <a href="https://doi.org/10.1073/pnas.2116722119">https://doi.org/10.1073/pnas.2116722119</a>.
</div>
<div id="ref-Andrews2010-pd" class="csl-entry" role="listitem">
Andrews, Simon. 2010. <span>“<span>FastQC</span>: A Quality Control Tool for High Throughput Sequence Data.”</span> <a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">http://www.bioinformatics.babraham.ac.uk/projects/fastqc/</a>.
</div>
<div id="ref-Antipov2016-xw" class="csl-entry" role="listitem">
Antipov, Dmitry, Anton Korobeynikov, Jeffrey S McLean, and Pavel A Pevzner. 2016. <span>“<span class="nocase">hybridSPAdes</span>: An Algorithm for Hybrid Assembly of Short and Long Reads.”</span> <em>Bioinformatics (Oxford, England)</em> 32 (7): 1009–15. <a href="https://doi.org/10.1093/bioinformatics/btv688">https://doi.org/10.1093/bioinformatics/btv688</a>.
</div>
<div id="ref-Borry2024-dz" class="csl-entry" role="listitem">
Borry, Maxime, Adrian Forsythe, Aida Andrades Valtueña, Alexander Hübner, Anan Ibrahim, Andrea Quagliariello, Anna E White, et al. 2024. <span>“Facilitating Accessible, Rapid, and Appropriate Processing of Ancient Metagenomic Data with <span>AMDirT</span>.”</span> <em>F1000Research</em> 12 (926): 926. <a href="https://doi.org/10.12688/f1000research.134798.2">https://doi.org/10.12688/f1000research.134798.2</a>.
</div>
<div id="ref-Borry2021-lt" class="csl-entry" role="listitem">
Borry, Maxime, Alexander Hübner, Adam B Rohrlach, and Christina Warinner. 2021. <span>“<span>PyDamage</span>: Automated Ancient Damage Identification and Estimation for Contigs in Ancient <span>DNA</span> de Novo Assembly.”</span> <em>PeerJ</em> 9 (July): e11845. <a href="https://doi.org/10.7717/peerj.11845">https://doi.org/10.7717/peerj.11845</a>.
</div>
<div id="ref-Bos2014-xe" class="csl-entry" role="listitem">
Bos, Kirsten I, Kelly M Harkins, Alexander Herbig, Mireia Coscolla, Nico Weber, Iñaki Comas, Stephen A Forrest, et al. 2014. <span>“Pre-Columbian Mycobacterial Genomes Reveal Seals as a Source of New World Human Tuberculosis.”</span> <em>Nature</em> 514 (7523): 494–97. <a href="https://doi.org/10.1038/nature13591">https://doi.org/10.1038/nature13591</a>.
</div>
<div id="ref-Breitwieser2018-xg" class="csl-entry" role="listitem">
Breitwieser, F P, D N Baker, and S L Salzberg. 2018. <span>“<span>KrakenUniq</span>: Confident and Fast Metagenomics Classification Using Unique k-Mer Counts.”</span> <em>Genome Biology</em> 19 (1): 198. <a href="https://doi.org/10.1186/s13059-018-1568-0">https://doi.org/10.1186/s13059-018-1568-0</a>.
</div>
<div id="ref-Chaumeil2022-xx" class="csl-entry" role="listitem">
Chaumeil, Pierre-Alain, Aaron J Mussig, Philip Hugenholtz, and Donovan H Parks. 2022. <span>“<span>GTDB</span>-Tk <span class="nocase">v2</span>: Memory Friendly Classification with the Genome Taxonomy Database.”</span> <em>Bioinformatics (Oxford, England)</em> 38 (23): 5315–16. <a href="https://doi.org/10.1093/bioinformatics/btac672">https://doi.org/10.1093/bioinformatics/btac672</a>.
</div>
<div id="ref-Chen2018-vg" class="csl-entry" role="listitem">
Chen, Shifu, Yanqing Zhou, Yaru Chen, and Jia Gu. 2018. <span>“Fastp: An Ultra-Fast All-in-One <span>FASTQ</span> Preprocessor.”</span> <em>Bioinformatics</em> 34 (17): i884–90. <a href="https://doi.org/10.1093/bioinformatics/bty560">https://doi.org/10.1093/bioinformatics/bty560</a>.
</div>
<div id="ref-Danecek2021-gj" class="csl-entry" role="listitem">
Danecek, Petr, James K Bonfield, Jennifer Liddle, John Marshall, Valeriu Ohan, Martin O Pollard, Andrew Whitwham, et al. 2021. <span>“Twelve Years of <span>SAMtools</span> and <span>BCFtools</span>.”</span> <em>GigaScience</em> 10 (2). <a href="https://doi.org/10.1093/gigascience/giab008">https://doi.org/10.1093/gigascience/giab008</a>.
</div>
<div id="ref-Di_Tommaso2017-xu" class="csl-entry" role="listitem">
Di Tommaso, Paolo, Maria Chatzou, Evan W Floden, Pablo Prieto Barja, Emilio Palumbo, and Cedric Notredame. 2017. <span>“Nextflow Enables Reproducible Computational Workflows.”</span> <em>Nature Biotechnology</em> 35 (4): 316–19. <a href="https://doi.org/10.1038/nbt.3820">https://doi.org/10.1038/nbt.3820</a>.
</div>
<div id="ref-Dimopoulos2022-tp" class="csl-entry" role="listitem">
Dimopoulos, Evangelos A, Alberto Carmagnini, Irina M Velsko, Christina Warinner, Greger Larson, Laurent A F Frantz, and Evan K Irving-Pease. 2022. <span>“<span>HAYSTAC</span>: A Bayesian Framework for Robust and Rapid Species Identification in High-Throughput Sequencing Data.”</span> <em>PLoS Computational Biology</em> 18 (9): e1010493. <a href="https://doi.org/10.1371/journal.pcbi.1010493">https://doi.org/10.1371/journal.pcbi.1010493</a>.
</div>
<div id="ref-Ewels2016-mv" class="csl-entry" role="listitem">
Ewels, Philip, Måns Magnusson, Sverker Lundin, and Max Käller. 2016. <span>“<span>MultiQC</span>: Summarize Analysis Results for Multiple Tools and Samples in a Single Report.”</span> <em>Bioinformatics</em> 32 (19): 3047–48. <a href="https://doi.org/10.1093/bioinformatics/btw354">https://doi.org/10.1093/bioinformatics/btw354</a>.
</div>
<div id="ref-Fellows_Yates2021-jl" class="csl-entry" role="listitem">
Fellows Yates, James A, Thiseas C Lamnidis, Maxime Borry, Aida Andrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U Garcia, Judith Neukamm, and Alexander Peltzer. 2021. <span>“Reproducible, Portable, and Efficient Ancient Genome Reconstruction with Nf-Core/Eager.”</span> <em>PeerJ</em> 9 (March): e10947. <a href="https://doi.org/10.7717/peerj.10947">https://doi.org/10.7717/peerj.10947</a>.
</div>
<div id="ref-Garcia2020-wq" class="csl-entry" role="listitem">
Garcia, Maxime, Szilveszter Juhos, Malin Larsson, Pall I Olason, Marcel Martin, Jesper Eisfeldt, Sebastian DiLorenzo, et al. 2020. <span>“Sarek: A Portable Workflow for Whole-Genome Sequencing Analysis of Germline and Somatic Variants.”</span> <em>F1000Research</em> 9 (63): 63. <a href="https://doi.org/10.12688/f1000research.16665.2">https://doi.org/10.12688/f1000research.16665.2</a>.
</div>
<div id="ref-Garrison2012-pv" class="csl-entry" role="listitem">
Garrison, Erik, and Gabor Marth. 2012. <span>“Haplotype-Based Variant Detection from Short-Read Sequencing.”</span> <em>arXiv [q-Bio.GN]</em>, July. <a href="http://arxiv.org/abs/1207.3907">http://arxiv.org/abs/1207.3907</a>.
</div>
<div id="ref-Gurevich2013-iq" class="csl-entry" role="listitem">
Gurevich, Alexey, Vladislav Saveliev, Nikolay Vyahhi, and Glenn Tesler. 2013. <span>“<span>QUAST</span>: Quality Assessment Tool for Genome Assemblies.”</span> <em>Bioinformatics (Oxford, England)</em> 29 (8): 1072–75. <a href="https://doi.org/10.1093/bioinformatics/btt086">https://doi.org/10.1093/bioinformatics/btt086</a>.
</div>
<div id="ref-Hanssen2024-ul" class="csl-entry" role="listitem">
Hanssen, Friederike, Maxime U Garcia, Lasse Folkersen, Anders Sune Pedersen, Francesco Lescai, Susanne Jodoin, Edmund Miller, et al. 2024. <span>“Scalable and Efficient <span>DNA</span> Sequencing Analysis on Different Compute Infrastructures Aiding Variant Discovery.”</span> <em>NAR Genomics and Bioinformatics</em> 6 (2): lqae031. <a href="https://doi.org/10.1093/nargab/lqae031">https://doi.org/10.1093/nargab/lqae031</a>.
</div>
<div id="ref-Herbig2016-rq" class="csl-entry" role="listitem">
Herbig, Alexander, Frank Maixner, Kirsten I Bos, Albert Zink, Johannes Krause, and Daniel H Huson. 2016. <span>“<span>MALT</span>: Fast Alignment and Analysis of Metagenomic <span>DNA</span> Sequence Data Applied to the Tyrolean Iceman.”</span> <em>bioRxiv</em>, April, 050559. <a href="https://doi.org/10.1101/050559">https://doi.org/10.1101/050559</a>.
</div>
<div id="ref-Hubler2019-qw" class="csl-entry" role="listitem">
Hübler, Ron, Felix M Key, Christina Warinner, Kirsten I Bos, Johannes Krause, and Alexander Herbig. 2019. <span>“<span>HOPS</span>: Automated Detection and Authentication of Pathogen <span>DNA</span> in Archaeological Remains.”</span> <em>Genome Biology</em> 20 (1): 280. <a href="https://doi.org/10.1186/s13059-019-1903-0">https://doi.org/10.1186/s13059-019-1903-0</a>.
</div>
<div id="ref-Hyatt2010-yv" class="csl-entry" role="listitem">
Hyatt, Doug, Gwo-Liang Chen, Philip F Locascio, Miriam L Land, Frank W Larimer, and Loren J Hauser. 2010. <span>“Prodigal: Prokaryotic Gene Recognition and Translation Initiation Site Identification.”</span> <em>BMC Bioinformatics</em> 11 (March): 119. <a href="https://doi.org/10.1186/1471-2105-11-119">https://doi.org/10.1186/1471-2105-11-119</a>.
</div>
<div id="ref-Kang2019-ld" class="csl-entry" role="listitem">
Kang, Dongwan D, Feng Li, Edward Kirton, Ashleigh Thomas, Rob Egan, Hong An, and Zhong Wang. 2019. <span>“<span>MetaBAT</span> 2: An Adaptive Binning Algorithm for Robust and Efficient Genome Reconstruction from Metagenome Assemblies.”</span> <em>PeerJ</em> 7 (e7359): e7359. <a href="https://doi.org/10.7717/peerj.7359">https://doi.org/10.7717/peerj.7359</a>.
</div>
<div id="ref-Kim2016-qc" class="csl-entry" role="listitem">
Kim, Daehwan, Li Song, Florian P Breitwieser, and Steven L Salzberg. 2016. <span>“Centrifuge: Rapid and Sensitive Classification of Metagenomic Sequences.”</span> <em>Genome Research</em> 26 (12): 1721–29. <a href="https://doi.org/10.1101/gr.210641.116">https://doi.org/10.1101/gr.210641.116</a>.
</div>
<div id="ref-Klapper2023-nv" class="csl-entry" role="listitem">
Klapper, Martin, Alexander Hübner, Anan Ibrahim, Ina Wasmuth, Maxime Borry, Veit G Haensch, Shuaibing Zhang, et al. 2023. <span>“Natural Products from Reconstructed Bacterial Genomes of the Middle and Upper Paleolithic.”</span> <em>Science (New York, N.Y.)</em>, May, eadf5300. <a href="https://doi.org/10.1126/science.adf5300">https://doi.org/10.1126/science.adf5300</a>.
</div>
<div id="ref-Krakau2022-we" class="csl-entry" role="listitem">
Krakau, Sabrina, Daniel Straub, Hadrien Gourlé, Gisela Gabernet, and Sven Nahnsen. 2022. <span>“Nf-Core/Mag: A Best-Practice Pipeline for Metagenome Hybrid Assembly and Binning.”</span> <em>NAR Genomics and Bioinformatics</em> 4 (1). <a href="https://doi.org/10.1093/nargab/lqac007">https://doi.org/10.1093/nargab/lqac007</a>.
</div>
<div id="ref-Li2015-lj" class="csl-entry" role="listitem">
Li, Dinghua, Chi-Man Liu, Ruibang Luo, Kunihiko Sadakane, and Tak-Wah Lam. 2015. <span>“<span>MEGAHIT</span>: An Ultra-Fast Single-Node Solution for Large and Complex Metagenomics Assembly via Succinct de Bruijn Graph.”</span> <em>Bioinformatics</em> 31 (10): 1674–76. <a href="https://doi.org/10.1093/bioinformatics/btv033">https://doi.org/10.1093/bioinformatics/btv033</a>.
</div>
<div id="ref-Louvel2016-jo" class="csl-entry" role="listitem">
Louvel, Guillaume, Clio Der Sarkissian, Kristian Hanghøj, and Ludovic Orlando. 2016. <span>“<span class="nocase">metaBIT</span>, an Integrative and Automated Metagenomic Pipeline for Analysing Microbial Profiles from High-Throughput Sequencing Shotgun Data.”</span> <em>Molecular Ecology Resources</em> 16 (6): 1415–27. <a href="https://doi.org/10.1111/1755-0998.12546">https://doi.org/10.1111/1755-0998.12546</a>.
</div>
<div id="ref-von-Meijenfeldt2019-qe" class="csl-entry" role="listitem">
Meijenfeldt, F A Bastiaan von, Ksenia Arkhipova, Diego D Cambuy, Felipe H Coutinho, and Bas E Dutilh. 2019. <span>“Robust Taxonomic Classification of Uncharted Microbial Sequences and Bins with <span>CAT</span> and <span>BAT</span>.”</span> <em>Genome Biology</em> 20 (1): 217. <a href="https://doi.org/10.1186/s13059-019-1817-x">https://doi.org/10.1186/s13059-019-1817-x</a>.
</div>
<div id="ref-Molder2021-et" class="csl-entry" role="listitem">
Mölder, Felix, Kim Philipp Jablonski, Brice Letcher, Michael B Hall, Christopher H Tomkins-Tinch, Vanessa Sochat, Jan Forster, et al. 2021. <span>“Sustainable Data Analysis with Snakemake.”</span> <em>F1000Research</em> 10 (January): 33. <a href="https://doi.org/10.12688/f1000research.29032.2">https://doi.org/10.12688/f1000research.29032.2</a>.
</div>
<div id="ref-Neuenschwander2023-aj" class="csl-entry" role="listitem">
Neuenschwander, Samuel, Diana I Cruz Dávalos, Lucas Anchieri, Bárbara Sousa da Mota, Davide Bozzi, Simone Rubinacci, Olivier Delaneau, Simon Rasmussen, and Anna-Sapfo Malaspinas. 2023. <span>“Mapache: A Flexible Pipeline to Map Ancient <span>DNA</span>.”</span> <em>Bioinformatics (Oxford, England)</em> 39 (2): btad028. <a href="https://doi.org/10.1093/bioinformatics/btad028">https://doi.org/10.1093/bioinformatics/btad028</a>.
</div>
<div id="ref-Neukamm2021-ul" class="csl-entry" role="listitem">
Neukamm, Judith, Alexander Peltzer, and Kay Nieselt. 2021. <span>“<span>DamageProfiler</span>: Fast Damage Pattern Calculation for Ancient <span>DNA</span>.”</span> <em>Bioinformatics</em> 37 (20): 3652–53. <a href="https://doi.org/10.1093/bioinformatics/btab190">https://doi.org/10.1093/bioinformatics/btab190</a>.
</div>
<div id="ref-Nurk2017-xh" class="csl-entry" role="listitem">
Nurk, Sergey, Dmitry Meleshko, Anton Korobeynikov, and Pavel A Pevzner. 2017. <span>“<span class="nocase">metaSPAdes</span>: A New Versatile Metagenomic Assembler.”</span> <em>Genome Research</em> 27 (5): 824–34. <a href="https://doi.org/10.1101/gr.213959.116">https://doi.org/10.1101/gr.213959.116</a>.
</div>
<div id="ref-Orakov2021-yq" class="csl-entry" role="listitem">
Orakov, Askarbek, Anthony Fullam, Luis Pedro Coelho, Supriya Khedkar, Damian Szklarczyk, Daniel R Mende, Thomas S B Schmidt, and Peer Bork. 2021. <span>“<span>GUNC</span>: Detection of Chimerism and Contamination in Prokaryotic Genomes.”</span> <em>Genome Biology</em> 22 (1): 178. <a href="https://doi.org/10.1186/s13059-021-02393-0">https://doi.org/10.1186/s13059-021-02393-0</a>.
</div>
<div id="ref-Parks2015-zg" class="csl-entry" role="listitem">
Parks, Donovan H, Michael Imelfort, Connor T Skennerton, Philip Hugenholtz, and Gene W Tyson. 2015. <span>“<span>CheckM</span>: Assessing the Quality of Microbial Genomes Recovered from Isolates, Single Cells, and Metagenomes.”</span> <em>Genome Research</em> 25 (7): 1043–55. <a href="https://doi.org/10.1101/gr.186072.114">https://doi.org/10.1101/gr.186072.114</a>.
</div>
<div id="ref-Peltzer2016-ov" class="csl-entry" role="listitem">
Peltzer, Alexander, Günter Jäger, Alexander Herbig, Alexander Seitz, Christian Kniep, Johannes Krause, and Kay Nieselt. 2016. <span>“<span>EAGER</span>: Efficient Ancient Genome Reconstruction.”</span> <em>Genome Biology</em> 17 (1): 1–14. <a href="https://doi.org/10.1186/s13059-016-0918-z">https://doi.org/10.1186/s13059-016-0918-z</a>.
</div>
<div id="ref-Pochon2022-hj" class="csl-entry" role="listitem">
Pochon, Zoé, Nora Bergfeldt, Emrah Kırdök, Mário Vicente, Thijessen Naidoo, Tom van der Valk, N Ezgi Altınışık, et al. 2022. <span>“<span class="nocase">aMeta</span>: An Accurate and Memory-Efficient Ancient Metagenomic Profiling Workflow.”</span> <em>bioRxiv</em>. <a href="https://doi.org/10.1101/2022.10.03.510579">https://doi.org/10.1101/2022.10.03.510579</a>.
</div>
<div id="ref-Poplin2018-yq" class="csl-entry" role="listitem">
Poplin, Ryan, Valentin Ruano-Rubio, Mark A DePristo, Tim J Fennell, Mauricio O Carneiro, Geraldine A Van der Auwera, David E Kling, et al. 2018. <span>“Scaling Accurate Genetic Variant Discovery to Tens of Thousands of Samples.”</span> <em>bioRxiv</em>, July, 201178. <a href="https://doi.org/10.1101/201178">https://doi.org/10.1101/201178</a>.
</div>
<div id="ref-Quinlan2010-lf" class="csl-entry" role="listitem">
Quinlan, Aaron R, and Ira M Hall. 2010. <span>“<span>BEDTools</span>: A Flexible Suite of Utilities for Comparing Genomic Features.”</span> <em>Bioinformatics</em> 26 (6): 841–42. <a href="https://doi.org/10.1093/bioinformatics/btq033">https://doi.org/10.1093/bioinformatics/btq033</a>.
</div>
<div id="ref-Schubert2014-ps" class="csl-entry" role="listitem">
Schubert, Mikkel, Luca Ermini, Clio Der Sarkissian, Hákon Jónsson, Aurélien Ginolhac, Robert Schaefer, Michael D Martin, et al. 2014. <span>“Characterization of Ancient and Modern Genomes by <span>SNP</span> Detection and Phylogenomic and Metagenomic Analysis Using <span>PALEOMIX</span>.”</span> <em>Nature Protocols</em> 9 (5): 1056–82. <a href="https://doi.org/10.1038/nprot.2014.063">https://doi.org/10.1038/nprot.2014.063</a>.
</div>
<div id="ref-Schubert2016-qv" class="csl-entry" role="listitem">
Schubert, Mikkel, Stinus Lindgreen, and Ludovic Orlando. 2016. <span>“<span>AdapterRemoval</span> <span class="nocase">v2</span>: Rapid Adapter Trimming, Identification, and Read Merging.”</span> <em>BMC Research Notes</em> 9 (February): 88. <a href="https://doi.org/10.1186/s13104-016-1900-2">https://doi.org/10.1186/s13104-016-1900-2</a>.
</div>
<div id="ref-Seemann2014-ee" class="csl-entry" role="listitem">
Seemann, Torsten. 2014. <span>“Prokka: Rapid Prokaryotic Genome Annotation.”</span> <em>Bioinformatics</em> 30 (14): 2068–69. <a href="https://doi.org/10.1093/bioinformatics/btu153">https://doi.org/10.1093/bioinformatics/btu153</a>.
</div>
<div id="ref-Sieber2018-jt" class="csl-entry" role="listitem">
Sieber, Christian M K, Alexander J Probst, Allison Sharrar, Brian C Thomas, Matthias Hess, Susannah G Tringe, and Jillian F Banfield. 2018. <span>“Recovery of Genomes from Metagenomes via a Dereplication, Aggregation and Scoring Strategy.”</span> <em>Nature Microbiology</em> 3 (7): 836–43. <a href="https://doi.org/10.1038/s41564-018-0171-1">https://doi.org/10.1038/s41564-018-0171-1</a>.
</div>
<div id="ref-Simao2015-bs" class="csl-entry" role="listitem">
Simão, Felipe A, Robert M Waterhouse, Panagiotis Ioannidis, Evgenia V Kriventseva, and Evgeny M Zdobnov. 2015. <span>“<span>BUSCO</span>: Assessing Genome Assembly and Annotation Completeness with Single-Copy Orthologs.”</span> <em>Bioinformatics (Oxford, England)</em> 31 (19): 3210–12. <a href="https://doi.org/10.1093/bioinformatics/btv351">https://doi.org/10.1093/bioinformatics/btv351</a>.
</div>
<div id="ref-Steinegger2017-qt" class="csl-entry" role="listitem">
Steinegger, Martin, and Johannes Söding. 2017. <span>“<span>MMseqs2</span> Enables Sensitive Protein Sequence Searching for the Analysis of Massive Data Sets.”</span> <em>Nature Biotechnology</em> 35 (11): 1026–28. <a href="https://doi.org/10.1038/nbt.3988">https://doi.org/10.1038/nbt.3988</a>.
</div>
<div id="ref-Uritskiy2018-ut" class="csl-entry" role="listitem">
Uritskiy, Gherman V, Jocelyne DiRuggiero, and James Taylor. 2018. <span>“<span>MetaWRAP</span>-a Flexible Pipeline for Genome-Resolved Metagenomic Data Analysis.”</span> <em>Microbiome</em> 6 (1): 158. <a href="https://doi.org/10.1186/s40168-018-0541-1">https://doi.org/10.1186/s40168-018-0541-1</a>.
</div>
<div id="ref-Vagene2018-px" class="csl-entry" role="listitem">
Vågene, Åshild J, Alexander Herbig, Michael G Campana, Nelly M Robles García, Christina Warinner, Susanna Sabin, Maria A Spyrou, et al. 2018. <span>“Salmonella Enterica Genomes from Victims of a Major Sixteenth-Century Epidemic in Mexico.”</span> <em>Nature Ecology &amp; Evolution</em> 2 (3): 520–28. <a href="https://doi.org/10.1038/s41559-017-0446-6">https://doi.org/10.1038/s41559-017-0446-6</a>.
</div>
<div id="ref-Wood2019-mf" class="csl-entry" role="listitem">
Wood, Derrick E, Jennifer Lu, and Ben Langmead. 2019. <span>“Improved Metagenomic Analysis with Kraken 2.”</span> <em>Genome Biology</em> 20 (1): 257. <a href="https://doi.org/10.1186/s13059-019-1891-0">https://doi.org/10.1186/s13059-019-1891-0</a>.
</div>
<div id="ref-Wratten2021-es" class="csl-entry" role="listitem">
Wratten, Laura, Andreas Wilm, and Jonathan Göke. 2021. <span>“Reproducible, Scalable, and Shareable Analysis Pipelines with Bioinformatics Workflow Managers.”</span> <em>Nature Methods</em> 18 (10): 1161–68. <a href="https://doi.org/10.1038/s41592-021-01254-9">https://doi.org/10.1038/s41592-021-01254-9</a>.
</div>
<div id="ref-Wu2015-bz" class="csl-entry" role="listitem">
Wu, Yu-Wei, Blake A Simmons, and Steven W Singer. 2015. <span>“<span>MaxBin</span> 2.0: An Automated Binning Algorithm to Recover Genomes from Multiple Metagenomic Datasets.”</span> <em>Bioinformatics</em> 32 (4): 605–7. <a href="https://doi.org/10.1093/bioinformatics/btv638">https://doi.org/10.1093/bioinformatics/btv638</a>.
</div>
<div id="ref-Yu2020-zw" class="csl-entry" role="listitem">
Yu, He, Maria A Spyrou, Marina Karapetian, Svetlana Shnaider, Rita Radzevičiūtė, Kathrin Nägele, Gunnar U Neumann, et al. 2020. <span>“Paleolithic to Bronze Age Siberians Reveal Connections with First Americans and Across Eurasia.”</span> <em>Cell</em> 181 (6): 1232–1245.e20. <a href="https://doi.org/10.1016/j.cell.2020.04.037">https://doi.org/10.1016/j.cell.2020.04.037</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/spaam-community\.github\.org\/intro-to-ancient-metagenomics-book");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./accessing-ancient-metagenomic-data.html" class="pagination-link" aria-label="Accessing Ancient Metagenomic Data">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Accessing Ancient Metagenomic Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./deprecated-chapters.html" class="pagination-link" aria-label="Deprecated Chapters">
        <span class="nav-page-text">Deprecated Chapters</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2024 SPAAM Community &amp; Authors with ❤️. Available under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>. Source material <a href="https://github.com/SPAAM-community/intro-to-ancient-metagenomics-book">here</a>.</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>