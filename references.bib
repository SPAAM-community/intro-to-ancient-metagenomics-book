@ARTICLE{Schuster2008-qx,
  title    = "Next-generation sequencing transforms today's biology",
  author   = "Schuster, Stephan C",
  journal  = "Nature methods",
  volume   =  5,
  number   =  1,
  pages    = "16--18",
  abstract = "A new generation of non-Sanger-based sequencing technologies has
              delivered on its promise of sequencing DNA at unprecedented speed,
              thereby enabling impressive scientific achievements and novel
              biological applications. However, before stepping into the
              limelight, next-generation sequencing had to overcome the inertia
              of a field that relied on Sanger-sequencing for 30 years.",
  month    =  jan,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nmeth1156",
  doi      = "10.1038/nmeth1156",
  issn     = "1548-7105,1548-7091",
  language = "en",
  pmid     =  18165802
}

@ARTICLE{Shendure2008-fh,
  title    = "Next-generation {DNA} sequencing",
  author   = "Shendure, Jay and Ji, Hanlee",
  journal  = "Nature biotechnology",
  volume   =  26,
  number   =  10,
  pages    = "1135--1145",
  abstract = "DNA sequence represents a single format onto which a broad range
              of biological phenomena can be projected for high-throughput data
              collection. Over the past three years, massively parallel DNA
              sequencing platforms have become widely available, reducing the
              cost of DNA sequencing by over two orders of magnitude, and
              democratizing the field by putting the sequencing capacity of a
              major genome center in the hands of individual investigators.
              These new technologies are rapidly evolving, and near-term
              challenges include the development of robust protocols for
              generating sequencing libraries, building effective new approaches
              to data-analysis, and often a rethinking of experimental design.
              Next-generation DNA sequencing has the potential to dramatically
              accelerate biological and biomedical research, by enabling the
              comprehensive analysis of genomes, transcriptomes and interactomes
              to become inexpensive, routine and widespread, rather than
              requiring significant production-scale efforts.",
  month    =  oct,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nbt1486",
  doi      = "10.1038/nbt1486",
  issn     = "1546-1696,1087-0156",
  language = "en",
  pmid     =  18846087
}

@ARTICLE{Slatko2018-hg,
  title    = "Overview of Next-Generation Sequencing Technologies",
  author   = "Slatko, Barton E and Gardner, Andrew F and Ausubel, Frederick M",
  journal  = "Current protocols in molecular biology / edited by Frederick M.
              Ausubel ... [et al.]",
  volume   =  122,
  number   =  1,
  pages    = "e59",
  abstract = "High throughput DNA sequencing methodology (next generation
              sequencing; NGS) has rapidly evolved over the past 15 years and
              new methods are continually being commercialized. As the
              technology develops, so do increases in the number of
              corresponding applications for basic and applied science. The
              purpose of this review is to provide a compendium of NGS
              methodologies and associated applications. Each brief discussion
              is followed by web links to the manufacturer and/or web-based
              visualizations. Keyword searches, such as with Google, may also
              provide helpful internet links and information. © 2018 by John
              Wiley \& Sons, Inc.",
  month    =  apr,
  year     =  2018,
  url      = "http://dx.doi.org/10.1002/cpmb.59",
  keywords = "NGS; Sanger sequencing; next-generation sequencing",
  doi      = "10.1002/cpmb.59",
  issn     = "1934-3647,1934-3639",
  pmc      = "PMC6020069",
  language = "en",
  pmid     =  29851291
}

@ARTICLE{Van_Dijk2014-ep,
  title    = "Ten years of next-generation sequencing technology",
  author   = "van Dijk, Erwin L and Auger, Hélène and Jaszczyszyn, Yan and
              Thermes, Claude",
  journal  = "Trends in genetics",
  volume   =  30,
  number   =  9,
  pages    = "418--426",
  abstract = "Ten years ago next-generation sequencing (NGS) technologies
              appeared on the market. During the past decade, tremendous
              progress has been made in terms of speed, read length, and
              throughput, along with a sharp reduction in per-base cost.
              Together, these advances democratized NGS and paved the way for
              the development of a large number of novel NGS applications in
              basic science as well as in translational research areas such as
              clinical diagnostics, agrigenomics, and forensic science. Here we
              provide an overview of the evolution of NGS and discuss the most
              significant improvements in sequencing technologies and library
              preparation protocols. We also explore the current landscape of
              NGS applications and provide a perspective for future
              developments.",
  month    =  sep,
  year     =  2014,
  url      = "http://dx.doi.org/10.1016/j.tig.2014.07.001",
  keywords = "ChIP-seq; DNA-seq; NGS library preparation; Next-generation
              sequencing (NGS); RNA-seq; genomics",
  doi      = "10.1016/j.tig.2014.07.001",
  issn     = "0168-9525",
  language = "en",
  pmid     =  25108476
}

@ARTICLE{Kircher2012-fg,
  title    = "Double indexing overcomes inaccuracies in multiplex sequencing on
              the Illumina platform",
  author   = "Kircher, Martin and Sawyer, Susanna and Meyer, Matthias",
  journal  = "Nucleic acids research",
  volume   =  40,
  number   =  1,
  pages    = "e3",
  abstract = "Due to the increasing throughput of current DNA sequencing
              instruments, sample multiplexing is necessary for making
              economical use of available sequencing capacities. A widely used
              multiplexing strategy for the Illumina Genome Analyzer utilizes
              sample-specific indexes, which are embedded in one of the library
              adapters. However, this and similar multiplex approaches come with
              a risk of sample misidentification. By introducing indexes into
              both library adapters (double indexing), we have developed a
              method that reveals the rate of sample misidentification within
              current multiplex sequencing experiments. With ~0.3\% these rates
              are orders of magnitude higher than expected and may severely
              confound applications in cancer genomics and other fields
              requiring accurate detection of rare variants. We identified the
              occurrence of mixed clusters on the flow as the predominant source
              of error. The accuracy of sample identification is further
              impaired if indexed oligonucleotides are cross-contaminated or if
              indexed libraries are amplified in bulk. Double-indexing
              eliminates these problems and increases both the scope and
              accuracy of multiplex sequencing on the Illumina platform.",
  month    =  jan,
  year     =  2012,
  url      = "http://dx.doi.org/10.1093/nar/gkr771",
  doi      = "10.1093/nar/gkr771",
  issn     = "1362-4962,0305-1048",
  pmc      = "PMC3245947",
  pmid     =  22021376
}

@ARTICLE{Meyer2010-qc,
  title    = "Illumina sequencing library preparation for highly multiplexed
              target capture and sequencing",
  author   = "Meyer, Matthias and Kircher, Martin",
  journal  = "Cold Spring Harbor protocols",
  volume   =  2010,
  number   =  6,
  pages    = "db.prot5448",
  abstract = "The large amount of DNA sequence data generated by high-throughput
              sequencing technologies often allows multiple samples to be
              sequenced in parallel on a single sequencing run. This is
              particularly true if subsets of the genome are studied rather than
              complete genomes. In recent years, target capture from sequencing
              libraries has largely replaced polymerase chain reaction (PCR) as
              the preferred method of target enrichment. Parallelizing target
              capture and sequencing for multiple samples requires the
              incorporation of sample-specific barcodes into sequencing
              libraries, which is necessary to trace back the sample source of
              each sequence. This protocol describes a fast and reliable method
              for the preparation of barcoded (``indexed'') sequencing libraries
              for Illumina's Genome Analyzer platform. The protocol avoids
              expensive commercial library preparation kits and can be performed
              in a 96-well plate setup using multi-channel pipettes, requiring
              not more than two or three days of lab work. Libraries can be
              prepared from any type of double-stranded DNA, even if present in
              subnanogram quantity.",
  month    =  jun,
  year     =  2010,
  url      = "http://dx.doi.org/10.1101/pdb.prot5448",
  doi      = "10.1101/pdb.prot5448",
  issn     = "1559-6095,1940-3402",
  pmid     =  20516186
}

@ARTICLE{Ma2019-lg,
  title    = "Analysis of error profiles in deep next-generation sequencing data",
  author   = "Ma, Xiaotu and Shao, Ying and Tian, Liqing and Flasch, Diane A and
              Mulder, Heather L and Edmonson, Michael N and Liu, Yu and Chen,
              Xiang and Newman, Scott and Nakitandwe, Joy and Li, Yongjin and
              Li, Benshang and Shen, Shuhong and Wang, Zhaoming and Shurtleff,
              Sheila and Robison, Leslie L and Levy, Shawn and Easton, John and
              Zhang, Jinghui",
  journal  = "Genome biology",
  volume   =  20,
  number   =  1,
  pages    =  50,
  abstract = "BACKGROUND: Sequencing errors are key confounding factors for
              detecting low-frequency genetic variants that are important for
              cancer molecular diagnosis, treatment, and surveillance using deep
              next-generation sequencing (NGS). However, there is a lack of
              comprehensive understanding of errors introduced at various steps
              of a conventional NGS workflow, such as sample handling, library
              preparation, PCR enrichment, and sequencing. In this study, we use
              current NGS technology to systematically investigate these
              questions. RESULTS: By evaluating read-specific error
              distributions, we discover that the substitution error rate can be
              computationally suppressed to 10-5 to 10-4, which is 10- to
              100-fold lower than generally considered achievable (10-3) in the
              current literature. We then quantify substitution errors
              attributable to sample handling, library preparation, enrichment
              PCR, and sequencing by using multiple deep sequencing datasets. We
              find that error rates differ by nucleotide substitution types,
              ranging from 10-5 for A>C/T>G, C>A/G>T, and C>G/G>C changes to
              10-4 for A>G/T>C changes. Furthermore, C>T/G>A errors exhibit
              strong sequence context dependency, sample-specific effects
              dominate elevated C>A/G>T errors, and target-enrichment PCR led to
              ~ 6-fold increase of overall error rate. We also find that more
              than 70\% of hotspot variants can be detected at 0.1 ~ 0.01\%
              frequency with the current NGS technology by applying in silico
              error suppression. CONCLUSIONS: We present the first comprehensive
              analysis of sequencing error sources in conventional NGS
              workflows. The error profiles revealed by our study highlight new
              directions for further improving NGS analysis accuracy both
              experimentally and computationally, ultimately enhancing the
              precision of deep sequencing.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1186/s13059-019-1659-6",
  keywords = "Deep sequencing; Detection; Error rate; Hotspot mutation;
              Subclonal; Substitution",
  doi      = "10.1186/s13059-019-1659-6",
  issn     = "1465-6906",
  pmc      = "PMC6417284",
  language = "en",
  pmid     =  30867008
}
@UNPUBLISHED{Sinha2017-zo,
  title    = "Index switching causes “spreading-of-signal” among multiplexed
              samples in Illumina {HiSeq} 4000 {DNA} sequencing",
  author   = "Sinha, Rahul and Stanley, Geoff and Gulati, Gunsagar Singh and
              Ezran, Camille and Travaglini, Kyle Joseph and Wei, Eric and Chan,
              Charles Kwok Fai and Nabhan, Ahmad N and Su, Tianying and
              Morganti, Rachel Marie and Conley, Stephanie Diana and Chaib,
              Hassan and Red-Horse, Kristy and Longaker, Michael T and Snyder,
              Michael P and Krasnow, Mark A and Weissman, Irving L",
  journal  = "bioRxiv",
  pages    =  125724,
  abstract = "Illumina-based next generation sequencing (NGS) has accelerated
              biomedical discovery through its ability to generate thousands of
              gigabases of sequencing output per run at a fraction of the time
              and cost of conventional technologies. The process typically
              involves four basic steps: library preparation, cluster
              generation, sequencing, and data analysis. In 2015, a new
              chemistry of cluster generation was introduced in the newer
              Illumina machines (HiSeq 3000/4000/X Ten) called exclusion
              amplification (ExAmp), which was a fundamental shift from the
              earlier method of random cluster generation by bridge
              amplification on a non-patterned flow cell. The ExAmp chemistry,
              in conjunction with patterned flow cells containing nanowells at
              fixed locations, increases cluster density on the flow cell,
              thereby reducing the cost per run. It also increases sequence read
              quality, especially for longer read lengths (up to 150 base
              pairs). This advance has been widely adopted for genome sequencing
              because greater sequencing depth can be achieved for lower cost
              without compromising the quality of longer reads. We show that
              this promising chemistry is problematic, however, when
              multiplexing samples. We discovered that up to 5-10\% of
              sequencing reads (or signals) are incorrectly assigned from a
              given sample to other samples in a multiplexed pool. We provide
              evidence that this “spreading-of-signals” arises from low levels
              of free index primers present in the pool. These index primers can
              prime pooled library fragments at random via complementary 3′
              ends, and get extended by DNA polymerase, creating a new library
              molecule with a new index before binding to the patterned flow
              cell to generate a cluster for sequencing. This causes the
              resulting read from that cluster to be assigned to a different
              sample, causing the spread of signals within multiplexed samples.
              We show that low levels of free index primers persist after the
              most common library purification procedure recommended by
              Illumina, and that the amount of signal spreading among samples is
              proportional to the level of free index primer present in the
              library pool. This artifact causes homogenization and
              misclassification of cells in single cell RNA-seq experiments.
              Therefore, all data generated in this way must now be carefully
              re-examined to ensure that “spreading-of-signals” has not
              compromised data analysis and conclusions. Re-sequencing samples
              using an older technology that uses conventional bridge
              amplification for cluster generation, or improved library cleanup
              strategies to remove free index primers, can minimize or eliminate
              this signal spreading artifact.",
  month    =  apr,
  year     =  2017,
  url      = "http://dx.doi.org/10.1101/125724",
  doi      = "10.1101/125724",
  language = "en"
}

@ARTICLE{Van_der_Valk2019-to,
  title    = "Index hopping on the Illumina {HiseqX} platform and its
              consequences for ancient {DNA} studies",
  author   = "van der Valk, Tom and Vezzi, Francesco and Ormestad, Mattias and
              Dalén, Love and Guschanski, Katerina",
  journal  = "Molecular ecology resources",
  abstract = "The high-throughput capacities of the Illumina sequencing
              platforms and the possibility to label samples individually have
              encouraged wide use of sample multiplexing. However, this practice
              results in read misassignment (usually <1\%) across samples
              sequenced on the same lane. Alarmingly high rates of read
              misassignment of up to 10\% were reported for lllumina sequencing
              machines with exclusion amplification chemistry. This may make use
              of these platforms prohibitive, particularly in studies that rely
              on low-quantity and low-quality samples, such as historical and
              archaeological specimens. Here, we use barcodes, short sequences
              that are ligated to both ends of the DNA insert, to directly
              quantify the rate of index hopping in 100-year old
              museum-preserved gorilla (Gorilla beringei) samples. Correcting
              for multiple sources of noise, we identify on average 0.470\% of
              reads containing a hopped index. We show that sample-specific
              quantity of misassigned reads depends on the number of reads that
              any given sample contributes to the total sequencing pool, so that
              samples with few sequenced reads receive the greatest proportion
              of misassigned reads. This particularly affects ancient DNA
              samples, as these frequently differ in their DNA quantity and
              endogenous content. Through simulations we show that even low
              rates of index hopping, as reported here, can lead to biases in
              ancient DNA studies when multiplexing samples with vastly
              different quantities of endogenous material.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1111/1755-0998.13009",
  keywords = "ancient DNA; index switching; multiplexing; museum specimens;
              next-generation sequencing; read misassignment",
  doi      = "10.1111/1755-0998.13009",
  issn     = "1755-0998,1755-098X",
  language = "en",
  pmid     =  30848092
}

@ARTICLE{Ju2006-cl,
  title    = "Four-color {DNA} sequencing by synthesis using cleavable
              fluorescent nucleotide reversible terminators",
  author   = "Ju, Jingyue and Kim, Dae Hyun and Bi, Lanrong and Meng, Qinglin
              and Bai, Xiaopeng and Li, Zengmin and Li, Xiaoxu and Marma, Mong
              Sano and Shi, Shundi and Wu, Jian and Edwards, John R and Romu,
              Aireen and Turro, Nicholas J",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  103,
  number   =  52,
  pages    = "19635--19640",
  abstract = "DNA sequencing by synthesis (SBS) on a solid surface during
              polymerase reaction offers a paradigm to decipher DNA sequences.
              We report here the construction of such a DNA sequencing system
              using molecular engineering approaches. In this approach, four
              nucleotides (A, C, G, T) are modified as reversible terminators by
              attaching a cleavable fluorophore to the base and capping the
              3'-OH group with a small chemically reversible moiety so that they
              are still recognized by DNA polymerase as substrates. We found
              that an allyl moiety can be used successfully as a linker to
              tether a fluorophore to 3'-O-allyl-modified nucleotides, forming
              chemically cleavable fluorescent nucleotide reversible
              terminators, 3'-O-allyl-dNTPs-allyl-fluorophore, for application
              in SBS. The fluorophore and the 3'-O-allyl group on a DNA
              extension product, which is generated by incorporating
              3'-O-allyl-dNTPs-allyl-fluorophore in a polymerase reaction, are
              removed simultaneously in 30 s by Pd-catalyzed deallylation in
              aqueous buffer solution. This one-step dual-deallylation reaction
              thus allows the reinitiation of the polymerase reaction and
              increases the SBS efficiency. DNA templates consisting of
              homopolymer regions were accurately sequenced by using this class
              of fluorescent nucleotide analogues on a DNA chip and a four-color
              fluorescent scanner.",
  month    =  dec,
  year     =  2006,
  url      = "http://dx.doi.org/10.1073/pnas.0609513103",
  doi      = "10.1073/pnas.0609513103",
  pmc      = "PMC1702316",
  pmid     =  17170132,
  issn     = "0027-8424",
  language = "en"
}
